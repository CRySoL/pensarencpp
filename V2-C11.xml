<?xml  version="1.0" encoding="iso-8859-1"?>
<!-- -*- sgml -*- -->
<!--
  Editor:              Emacs 22/PSGML
  Traducción original: Cleto Martín Angelina
  Formateado DocBook:  
-->

<!-- original de referencia en:
http://arco.inf-cr.uclm.es/~david.villa/pensar_en_C++/TICv2/html/TicV2.html#_Toc53985862
-->

<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
                 "http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd">

<chapter 
  xmlns:xi="http://www.w3.org/2001/XInclude"
  id="C11">


  <!-- Concurrency -->
  <title>Concurrencia</title>

  <!--
  Objects provide a way to divide a program into independent
  sections. Often, you also need to partition a program into separate,
  independently running subtasks.
  -->

  <para>
  Los objetos ofrecen una forma de dividir un programa en diferentes
  secciones. A menudo, también es necesario dividir un programa,
  independientemente de las subtareas en ejecución.
  </para>

  <!--
  Using multithreading, each of these independent subtasks is driven by
  a thread of execution, and you program as if each thread has the CPU
  to itself. An underlying mechanism is dividing up the CPU time for
  you, but in general, you don?t need to think about it, which helps to
  simplify programming with multiple threads.
  -->
  <para>
  Utilizando multihilado, un hilo de ejecución dirige cada una esas
  subtareas independientes, y puedes programar como si cada hilo tuviera
  su propia CPU. Un mecanismo interno reparte el tiempo de CPU por ti,
  pero en general, no necesitas pensar acerca de eso, lo que ayuda a
  simplificar la programación con múltiples hilos.
  </para>

  <!--
  A process is a self-contained program running within its own address
  space. A multitasking operating system can run more than one process
  (program) at a time, while making it look as if each one is chugging
  along on its own, by periodically switching the CPU from one task to
  another. A thread is a single sequential flow of control within a
  process. A single process can thus have multiple concurrently
  executing threads. Since the threads run within a single process, they
  share memory and other resources. The fundamental difficulty in
  writing multithreaded programs is coordinating the use of those
  resources between different threads.
  -->
  <para>
  Un proceso es un programa autocontenido en ejecución con su propio
  espacio de direcciones. Un sistema operativo multitarea puede ejecutar
  más de un proceso (programa) en el mismo tiempo, mientras ....., por
  medio de cambios periódicos de CPU de una tarea a otra. Un hilo es una
  simple flujo de control secuencial con un proceso. Un proceso puede
  tener de este modo múltiples hilos en ejecución concurrentes. Puesto
  que los hilos se ejecutan con un proceso simple, pueden compartir
  memoria y otros recursos.  La dificultad fundamental de escribir
  programas multihilados está en coordinar el uso de esos recursos entre
  los diferentes hilos.
  </para>

  <!--
  There are many possible uses for multithreading, but you?ll most often
  want to use it when you have some part of your program tied to a
  particular event or resource. To keep from holding up the rest of your
  program, you create a thread associated with that event or resource
  and let it run independently of the main program.
  -->
  <para>
  Hay muchas aplicaciones posibles para el multihilado, pero lo más
  usual es querer usarlo cuando tienes alguna parte de tu programa
  vinculada a un evento o recurso particular. Para evitar bloquear el
  resto de tu programa, creas un hilo asociado a ese evento o recurso y
  le permites ejecutarse independientemente del programa principal.
  </para>

  <!--
  Concurrent programming is like stepping into an entirely new world and
  learning a new programming language, or at least a new set of language
  concepts. With the appearance of thread support in most microcomputer
  operating systems, extensions for threads have also been appearing in
  programming languages or libraries. In all cases, thread programming:
  -->
  <para>
  La programación concurrente se como caminar en un mundo completamente
  nuevo y aprender un nuevo lenguaje de programación, o por lo menos un
  nuevo conjunto de conceptos del lenguaje. Con la aparición del soporte
  para los hilos en la mayoría de los sistemas operativos para
  microcomputadores, han aparecido también en los lenguajes de
  programación o librerías extensiones para los hilos.  En cualquier
  caso, programación hilada:
  </para>

  <!--
  1.  Seems mysterious and requires a shift in the way you think about
  programming.
  -->
  <para>
  1. Parece misteriosa y requiere un esfuerzo en la forma de pensar
  acerca de la programación.
  </para>

  <!--
  2.  Looks similar to thread support in other languages. When you
  understand threads, you understand a common tongue.
  -->
  <para>
  2. En otros lenguajes el soporte a los hilos es similar. Cuando
  entiendas los hilos, comprenderás una jerga común.
  </para>

  <!--
  Understanding concurrent programming is on the same order of
  difficulty as understanding polymorphism. If you apply some effort,
  you can fathom the basic mechanism, but it generally takes deep study
  and understanding to develop a true grasp of the subject. The goal of
  this chapter is to give you a solid foundation in the basics of
  concurrency so that you can understand the concepts and write
  reasonable multithreaded programs. Be aware that you can easily become
  overconfident. If you are writing anything complex, you will need to
  study dedicated books on the topic.
  -->
  <para>
  Comprender la programación concurrente está al mismo nivel de
  dificultad que comprender el polimorfismo. Si pones un poco de
  esfuerzo, podrás entender el mecanismo básico, pero generalmente
  necesitará de un entendimiento y estudio profundo para desarrollar una
  comprensión auténtica sobre el tema. La meta de este capítulo es darte
  una base sólida en los principios de concurrencia para que puedas
  entender los conceptos y escribir programas multihilados
  razonables. Sé consciente de que puedes confiarte fácilmente. Si vas a
  escribir algo complejo, necesitarás estudiar libros específicos sobre
  el tema.
  </para>


  <sect1>
    <!-- Motivation -->
    <title>Motivación</title>

  <!--
  One of the most compelling reasons for using concurrency is to produce
  a responsive user interface. Consider a program that performs some
  CPU-intensive operation and thus ends up ignoring user input and being
  unresponsive. The program needs to continue performing its operations,
  and at the same time it needs to return control to the user interface
  so that the program can respond to the user. If you have a ?quit?
  button, you don?t want to be forced to poll it in every piece of code
  you write in your program. (This would couple your quit button across
  the program and be a maintenance headache.) Yet you want the quit
  button to be responsive, as if you were checking it regularly.
  -->
  <para>
  Una de las razones más convincentes para usar concurrencia es crear
  una interfaz sensible al usuario. Considera un programa que realiza
  una operación de CPU intensiva y, de esta forma, termina ignorando la
  entrada del usuario y comienza a no responder. El programa necesita
  continuar controlandor sus operaciones, y al mismo tiempo necesita
  devolver el control al botón de la interfaz de usuario para que el
  programa pueda responder al usuario. Si tienes un botón de "Salir", no
  querrás estar forzado a sondearlo en todas las partes de código que
  escribas en tu programa. (Esto acoplaría tu botón de salir a lo largo
  del programa y sería un quebradero de cabeza a la hora de
  mantenerlo). .....
  </para>

  <!--
  A conventional function cannot continue performing its operations and
  at the same time return control to the rest of the program. In fact,
  this sounds like an impossibility, as if the CPU must be in two places
  at once, but this is precisely the illusion that concurrency provides
  (in the case of multiprocessor systems, this may be more than an
  illusion).
  -->
  <para>
  Una función convencional no puede continuar realizando sus operaciones
  y al mismo tiempo devolver el control al resto del programa. De hecho,
  suena a imposible, como si la CPU estuviera en dos lugares a la vez,
  pero esto es precisamente la "ilusión" que la concurrencia permite (en
  el caso de un sistema multiprocesador, debe haber más de una
  "ilusión").
  </para>

  <!--
  You can also use concurrency to optimize throughput. For example, you
  might be able to do important work while you?re stuck waiting for
  input to arrive on an I/O port. Without threading, the only reasonable
  solution is to poll the I/O port, which is awkward and can be
  difficult.
  -->
  <para>
  También puedes usar concurrencia para optimizar la carga de trabajo.
  Por ejemplo, podrías necesitar hacer algo importante mientras estás
  estancado esperando la llegada de una entrada del puerto I/O. Sin
  hilos, la única solución razonable es sondear los puertos I/O, que es
  costoso y puede ser difícil.
  </para>

  <!--
  If you have a multiprocessor machine, multiple threads can be
  distributed across multiple processors, which can dramatically improve
  throughput. This is often the case with powerful multiprocessor web
  servers, which can distribute large numbers of user requests across
  CPUs in a program that allocates one thread per request.
  -->
  <para>
  Si tienes una máquina multiprocesador, los múltiples hilos pueden ser
  distribuídos a lo largo de los múltiples procesadores, pudiendo
  mejorar considerablemente la carga de trabajo. Este es el típico caso
  de los potentes servidores web multiprocesdor, que pueden distribuir
  un gran número de peticiones de usuario por todas las CPUs en un
  programa que asigna un hilo por petición.
  </para>

  <!--
  A program that uses threads on a single-CPU machine is still just
  doing one thing at a time, so it must be theoretically possible to
  write the same program without using any threads. However,
  multithreading provides an important organizational benefit: The
  design of your program can be greatly simplified. Some types of
  problems, such as simulation?a video game, for example?are difficult
  to solve without support for concurrency.
  -->
  <para>
  Un programa que usa hilos en una máquina monoprocesador hará una cosa
  en un tiempo dado, por lo que es teóricamente posible escribir el
  mismo programa sin el uso de hilos. Sin embargo, el multihilado
  proporciona un beneficio de optimización importante: El diseño de un
  programa puede ser maravillosamente simple. Algunos tipos de
  problemas, como la simulación - un video juego, por ejemplo - son
  difíciles de resolver sin el soporte de la concurrencia.
  </para>

  <!--
  The threading model is a programming convenience to simplify juggling
  several operations at the same time within a single program: The CPU
  will pop around and give each thread some of its time.[148] Each
  thread has the consciousness of constantly having the CPU to itself,
  but the CPU?s time is actually sliced among all the threads. The
  exception is a program that is running on multiple CPU. But one of the
  great things about threading is that you are abstracted away from this
  layer, so your code does not need to know whether it is running on a
  single CPU or many.[149] Thus, using threads is a way to create
  transparently scalable programs?if a program is running too slowly,
  you can easily speed it up by adding CPUs to your
  computer. Multitasking and multithreading tend to be the most
  reasonable ways to utilize multiprocessor systems.
  -->
  <para>
  El modelo hilado es una comodidad de la programación para simplificar
  el manejo de muchas operaciones al mismo tiempo con un simple
  programa: La CPU desapilará y dará a cada hilo algo de su tiempo. Cada
  hilo tiene consciencia de que tiene un tiempo constante de uso de CPU,
  pero el tiempo de CPU está actualmente repartido entre todo los
  hilos. La excepción es un programa que se ejecuta sobre múltiples
  CPU's. Pero una de las cosas fabulosas que tiene el hilado es que te
  abstrae de esta capa, por lo que tu código no necesita saber si está
  ejecutándose sobre una sóla CPU o sobre varias.[149] De este modo,
  usar hilos es una manera de crear programas escalables de forma
  transparente - si un programa se está ejecutando demasiado despacio,
  puedes acelerarlo fácilmente añadiendo CPUs a tu ordenador. La
  multitarea y el multihilado tienden a ser las mejores opciones a
  utilizar en un sistema multiprocesador.
  </para>

  <!--
  Threading can reduce computing efficiency somewhat, but the net
  improvement in program design, resource balancing, and user
  convenience is often quite valuable. In general, threads enable you to
  create a more loosely coupled design; otherwise, parts of your code
  would be forced to pay explicit attention to tasks that would normally
  be handled by threads.
  -->
  <para>
  El uso de hilos puede reducir la eficiencia computacional un poco,
  pero el aumento neto en el diseño del programa, balanceo de recursos,
  y la comodidad del usuario a menudo es más valorado. En general, los
  hilos te permiten crear diseñor más desacoplados; de lo contrario, las
  partes de tu código estaría obligadas a prestar atención a tareas que
  podrías manejarlas con hilos normalmente.
  </para>
  </sect1>

  <sect1>
    <!-- : Concurrency in C++ -->
    <title>Concurrencia en C++</title>

    <!--
    When the C++ Standards Committee was creating the initial C++
    Standard, a concurrency mechanism was explicitly excluded because C
    didn?t have one and also because there were a number of competing
    approaches to implementing concurrency. It seemed too much of a
    constraint to force programmers to use only one of these.
    -->
    <para>
    Cuando el Comité de Estándares de C++ estaba creando el estándar
    inicial de C++, el mecanismo de concurrencia fue excluído de forma
    explícita porque C no tenía uno y también porque había varíos enfoques
    rivales acerca de su implementación. Parecía demasiado restrictivo
    forzar a los programadores a usar una sola alternativa.
    </para>

    <!--
    The alternative turned out to be worse, however. To use concurrency,
    you had to find and learn a library and deal with its idiosyncrasies
    and the uncertainties of working with a particular vendor. In
    addition, there was no guarantee that such a library would work on
    different compilers or across different platforms. Also, since
    concurrency was not part of the standard language, it was more
    difficult to find C++ programmers who also understood concurrent
    programming.
    -->
    <para>
    Sin embargo, la alternativa resultó ser peor. Para usar concurriencia,
    tenías que encontrar y aprender una librería y ocuparte de su
    indiosincrasia y las incertidumbres de trabajar con un vendedor
    particular. Además, no había garantía de que una librería funcionaría
    en diferentes compiladores o en distintas plataformas. También, desde
    que la concurrencia no formaba parte del estándar del lenguaje, fue
    más difícil encontrar programadores C++ que también entendieran la
    programación concurrente.
    </para>

    <!--
    Another influence may have been the Java language, which included
    concurrency in the core language. Although multithreading is still
    complicated, Java programmers tend to start learning and using it from
    the beginning.
    -->
    <para>
    Otra influencia pudo ser el lenguaje Java, que incluyó concurrencia en
    el núcleo del lenguaje. Aunque el multihilado is aún complicado, los
    programadores de Java tienden a empezar a aprenderlo y usarlo desde el
    principio.
    </para>

    <!--
    The C++ Standards Committee is considering the addition of concurrency
    support to the next iteration of C++, but at the time of this writing
    it is unclear what the library will look like. We decided to use the
    ZThread library as the basis for this chapter. We preferred the
    design, and it is open-source and freely available at
    http://zthread.sourceforge.net. Eric Crahen of IBM, the author of the
    ZThread library, was instrumental in creating this chapter.[150]
    -->
    <para>
    El Comité de Estándares de C++ está considerando incluir el soporte a
    la concurrencia en la siguiente iteración de C++, pero en el momento
    de este escrito no estaba claro qué aspecto tendrá la
    librería. Decidimos usar la librería ZThread como base para este
    capítulo. La escogimos por su diseño, y es open-source y gratuitamente
    descargable desde http://zthread.sourceforge.net. Eric Crahen de IBM,
    el autor de la librería ZThread, fue decisivo para crear este
    capítulo.[150]
    </para>

    <!--
    This chapter uses only a subset of the ZThread library, in order to
    convey the fundamental ideas of threading. The ZThread library
    contains significantly more sophisticated thread support than is shown
    here, and you should study that library further in order to fully
    understand its capabilities.
    -->
    <para>
    Este capítulo utiliza sólo un subgrupo de la librería ZThread, de
    acuerdo con el convenio de ideas fundamentales sobre los hilos. La
    librería ZThread contiene un soporte a los hilos significativamente
    más sofisticado que el que se muestra aquí, y deberías estudiar esa
    librería más profundamente para comprender completamente sus
    posibilidades.
    </para>

    <sect2>
      <!-- : Installing ZThreads -->
      <title>Instalación de ZThreads</title>

      <!--
      Please note that the ZThread library is an independent project and is
      not supported by the authors of this book; we are simply using the
      library in this chapter and cannot provide technical support for
      installation issues. See the ZThread web site for installation support
      and error reports.
      -->
      <para>
      Por favor, note que la librería ZThread es un proyecto independiente y
      no está soportada por el autor de este libro; simplemente estamos
      usando la librería en este capítulo y no podemos dar soporte técnico a
      las características de la instalación. Mira el sitio web de ZThread
      para obtener soporte en la instalación y reporte de errores.
      </para>

      <!--
      The ZThread library is distributed as source code. After downloading
      it (version 2.3 or greater) from the ZThread web site, you must first
      compile the library, and then configure your project to use the
      library.
      -->
      <para>
      La librería ZThread se distribuye como código fuente. Después de
      descargarla (versión 2.3 o superior) desde la web de ZThread, debes
      compilar la librería primero, y después configurar tu proyecto para
      que use la librería.
      -->
      </para>

      <!--
      The preferred method for compiling ZThreads for most flavors of UNIX
      (Linux, SunOS, Cygwin, etc.) is to use the configure script. After
      unpacking the files (using tar), simply execute:
      -->
      <para>
      El método habitual para compilar la librería ZThreads para los
      distintos sabores de UNIX (Linux, SunOS, Cygwin, etc) es usar un
      script de configuración. Después de desempaquetar los archivos (usando
      tar), simplemente ejecuta: ./configure &amp;&amp; make install
      </para>

      <!--
      from the main directory of the ZThreads archive to compile and install
      a copy of the library in the /usr/local directory. You can customize a
      number of options when using this script, including the locations of
      files. For details, use this command:
      -->
      <para>
      en el directorio principal de ZThreads para compilar e instalar una
      copia de la librería en directorio /usr/local. Puedes personalizar
      algunas opciones cuando uses el script, incluída la localización de
      los ficheros. Para más detalles, utiliza este comando: ./configure
      ?help
      </para>

      <!--
      The ZThreads code is structured to simplify compilation for other
      platforms and compilers (such as Borland, Microsoft, and
      Metrowerks). To do this, create a new project and add all the .cxx
      files in the src directory of the ZThreads archive to the list of
      files to be compiled. Also, be sure to include the include directory
      of the archive in the header search path for your project. The exact
      details will vary from compiler to compiler so you?ll need to be
      somewhat familiar with your toolset to be able to use this option.
      -->
      <para>
      El código de ZThreads está estructurado para simplificar la
      compilación para otras plataformas (como Borland, Microsoft y
      Metrowerks). Para hacer esto, crea un nuevo proyecto y añade todos los
      archivos .cxx en el directorio src de ZThreads a la lista de archivos
      a compilar.  Además, asegúrate de incluir el directorio incluído del
      archivo en la ruta de búsqueda de la cabecera para tu proyecto???. Los
      detalles exactos variarán de compilador en compilador, por lo que
      necesitarás estar algo familiarizado con tu conjunto de herramientas
      para ser capaz de utilizar esta opción.
      </para>

      <!--
      Once the compilation has succeeded, the next step is to create a
      project that uses the newly compiled library. First, let the compiler
      know where the headers are located so that your #include statements
      will work properly. Typically, you will add an option such as the
      following to your project:
      -->
      <para>
      Una vez la compilación ha finalizado con éxito, el siguiente paso es
      crear un proyecto que use la nueva librería compilada. Primero,
      permite al compilador saber donde están localizadas las cabeceras, por
      lo que tu instrucción #include funcionará
      correctamente. Habitualmente, necesitarás en tu proyecto una opción
      como se muestra:
      </para>

<programlisting>
-I/path/to/installation/include -->
</programlisting> 

      <!--
      If you used the configure script, the installation path will be
      whatever you selected for the prefix (which defaults to
      /usr/local). If you used one of the project files in the build
      directory, the installation path would simply be the path to the main
      directory of the ZThreads archive.
      -->
      <para>
      Si utilizaste el script de configuración, la ruta de instalación
      será el prefijo de la que definiste (por defecto, /usr/local). Si
      utilizaste uno de los archivos de proyecto en la creación del
      directorio, la ruta instalación debería ser simplemente la ruta al
      directorio principal del archivo ZThreads.
      </para>

      <!--
      Next, you?ll need to add an option to your project that will let the
      linker know where to find the library. If you used the configure
      script, this will look like:
      -->
      <para>
      Después, necesitarás añadir una opción a tu proyecto que permitirá al
      enlazador saber donde está la librería. Si usaste el script de
      configuración, se parecerá a lo siguiente:
      </para>


<programlisting>
-L/path/to/installation/lib ?lZThread
</programlisting>


      <!-- If you used one of the project files provided, this will look like: -->
      <para>
      Si usaste uno de los archivos del proyecto proporcionados, será
      similar a:
      </para>


<programlisting>
-L/path/to/installation/Debug ZThread.lib
</programlisting>


      <!--
      Again, if you used the configure script, the installation path will be
      whatever you selected for the prefix. If you used a provided project
      file, the path will be the path to the main directory of the ZThreads
      archive.
      -->
      <para>
      De nuevo, si usaste el script de configuración, la ruta de instalación
      s será el prefijo de la que definistes. Si su utilizaste un archivo
      del proyecto, la ruta será la misma que la del directorio principal de
      ZThreads.
      </para>

      <!--
      Note that if you?re using Linux, or if you are using Cygwin
      (www.cygwin.com) under Windows, you may not need to modify your
      include or library path; the installation process and defaults will
      often take care of everything for you.
      -->
      <para>
      Nota que si estás utilizando Linux, o Cygwin (www.cygwin.com) bajo
      Windows, no deberías necesitar modificar la ruta de include o de la
      librería; el proceso por defecto de instalación tendrá cuidado para
      hacerlo por ti, normalmente.
      </para>

      <!--
      Under Linux, you will probably need to add the following to your
      .bashrc so that the runtime system can find the shared library file
      LibZThread-x.x.so.O when it executes the programs in this chapter:
      -->
      <para>
	En GNU/Linux, es posible que necesites añadir lo siguiente a tu .bashrc
      para que el sistema pueda encontrar la el archivo de la
      librería compartida LibZThread-x.x.so.0 cuando ejecute programas de
      este capítulo.
      </para>


<programlisting>
export LD_LIBRARY_PATH=/usr/local/lib:${LD_LIBRARY_PATH}
</programlisting> 


      <!--
      (Assuming you used the default installation process and the shared
      library ended up in /user/local/lib; otherwise, change the path to
      your location).
      -->
      <para>
      (Asumiendo que utilizas el proceso de instalación por defecto y la
      librería compartida acaba en /user/local/lib/; en otro caso, cambia la
      ruta por tu localización.
      </para>

    </sect2>
    <sect2>
      <!-- : Defining Tasks -->
      <title>Definición de tareas</title>

      <!--
      A thread carries out a task, so you need a way to describe that
      task. The Runnable class provides a common interface to execute any
      arbitrary task. Here is the core of the ZThread Runnable class, which
      you will find in Runnable.h in the include directory, after installing
      the ZThread library:
      -->
      <para>
      Un hilo cumple con una tarea, por lo que necesitas un manera de
      describir esa tarea. La clase Runnable proporciona unas interfaces
      comunes a ejecutar para cualquier tarea. Aquí está el núcleo de las
      clase Runnable de ZThread, que la encontrarás en el archivo Runnable.h
      dentro del directorio incluído, después de instalar la librería
      ZThread:
      </para>


<programlisting>
class Runnable {
public:
  virtual void run() = 0;
  virtual ~Runnable() {}
};
</programlisting>


      <!--
      By making this an abstract base class, Runnable is easily combinable
      with a base class and other classes.
      -->
      <para>
      Al hacerla una clase base abstracta, Runnable es fácilmente combinable
      con una clase básica u otras clases.
      </para>

      <!--
      To define a task, simply inherit from the Runnable class and override
      run( ) to make the task do your bidding.
      -->
      <para>
      Para definir una tarea, simplemente hereda de la clase Runnable y
      sobreescribe run( ) para que la tarea haga lo que quieres.
      </para>

      <!--
      For example, the following LiftOff task displays the countdown before
      liftoff:
      -->
      <para>
      Por ejecomplo, la tarea LiftOff siguiente muestra la cuenta atrás
      antes de despegar:
      </para>


//: V2C11:LiftOff.h


      <!--
      The identifier id distinguishes between multiple instances of the
      task. If you only make a single instance, you can use the default
      value for ident. The destructor will allow you to see that a task is
      properly destroyed.
      -->
      <para>
	El identificador id sirve como distinción entre multiples instancias
      de la tarea. Si sólo quieres hacer una instancia, debes utilizar el
      valor por defecto para identificarla. El destructor te permitirá
      ver que tarea está destruída correctamente.
      </para>

      <!--
      In the following example, the task?s run( ) is not driven by a
      separate thread; it is simply called directly in main( ):
      -->
      <para>
      En el siguiente ejemplo, las tareas de run( ) no están dirigidas por
      hilos separados; directamente es una simple llamada en main( ):
      </para>


//: V2C11:NoThread.cpp


      <!--
      When a class is derived from Runnable, it must have a run( ) function,
      but that?s nothing special?it doesn?t produce any innate threading
      abilities.
      -->
      <para>
      Cuando una clase deriva de Runnable, debe tene una función run( ),
      pero no tiene nada de especial - no produce ninguna habibilidad innata
      en el hilo.
      </para>

      <!-- To achieve threading behavior, you must use the Thread class. -->
      <para>
      Para llevar a cabo el funcionamiento de los hilos, debes utilizas la
      clase Thread.
      </para>

    </sect2>
  </sect1>
  <sect1>
    <!-- : Using Threads -->
    <title>Utilización de los hilos</title>

    <!--
    To drive a Runnable object with a thread, you create a separate Thread
    object and hand a Runnable pointer to the Thread?s constructor. This
    performs the thread initialization and then calls the Runnable?s run(
    ) as an interruptible thread. By driving LiftOff with a Thread, the
    example below shows how any task can be run in the context of another
    thread:
    -->
    <para>
    Para controlar un objeto Runnable con un hilo, crea un objeto Thread
    separado y utiliza un pontero Runnable al constructor de Thread. Esto
    lleva a cabo la inicialización del hilo y, después, llama a run ( ) de
    Runnable como un hilo capaz de ser interrumpido. Manejando LiftOff con
    un hilo, el ejemplo siguiente muestra como cualquier tarea puede ser
    ejecutada en el contexto de cualquier otro hilo:
    </para>


//: V2C11:BasicThreads.cpp


    <!--
    Synchronization_Exception is part of the ZThread library and is the
    base class for all ZThread exceptions. It will be thrown if there is
    an error starting or using a thread.
    -->
    <para>
    Synchronization_Exception forma parte de la librería ZThread y la
    clase base para todas las excepciones de ZThread. Se lanzará si hay un
    error al crear o usar un hilo.
    </para>

    <!--
    A Thread constructor only needs a pointer to a Runnable
    object. Creating a Thread object will perform the necessary
    initialization for the thread and then call that Runnable?s run( )
    member function to start the task. Even though the Thread constructor
    is, in effect, making a call to a long-running function, that
    constructor quickly returns. In effect, you have made a member
    function call to LiftOff::run( ), and that function has not yet
    finished, but because LiftOff::run( ) is being executed by a different
    thread, you can still perform other operations in the main( )
    thread. (This ability is not restricted to the main( ) thread?any
    thread can start another thread.) You can see this by running the
    program. Even though LiftOff::run( ) has been called, the ?Waiting for
    LiftOff? message will appear before the countdown has completed. Thus,
    the program is running two functions at once?LiftOff::run( ) and main(
    ).
    -->
    <para>
      Un constructor de <classname>Thread</classname> sólo necesita un
      puntero a un objeto Runnable. Al crear un objeto
      <classname>Thread</classname> se efectuará la incialización
      necesaria del hilo y después se llamará a
      <function>Runnable::run()</function>
    </para>

    <!--
    You can easily add more threads to drive more tasks. Here, you can see
    how all the threads run in concert with one another:
    -->
    <para>
      Puede añadir más hilos fácilmente para controlar más tareas. A
      continuación, puede ver cómo los hilos se ejecutan con algún otro:
    </para>


//: V2C11:MoreBasicThreads.cpp


    <!--
    The second argument for the LiftOff constructor identifies each
    task. When you run the program, you?ll see that the execution of the
    different tasks is mixed together as the threads are swapped in and
    out. This swapping is automatically controlled by the thread
    scheduler. If you have multiple processors on your machine, the thread
    scheduler will quietly distribute the threads among the processors.
    -->
    <para>
      El segundo argumento del constructor
      de <classname>LiftOff</classname> identifica cada tarea. Cuando
      ejecute el programa, verá que la ejecución de las distintas
      tareas se mezclan a medida que los hilos entran y salen de su
      ejecución. Este intercambio está controlado automáticamente por
      el planificador de hilos. Si tiene múltiples procesadores en su
      máquina, el planificador de hilos distribuirá los hilos entre
      los procesadores de forma transparente.
    </para>

    <!--
    The for loop can seem a little strange at first because t is being
    created locally inside the for loop and then immediately goes out of
    scope and is destroyed. This makes it appear that the thread itself
    might be immediately lost, but you can see from the output that the
    threads are indeed running to conclusion. When you create a Thread
    object, the associated thread is registered with the threading system,
    which keeps it alive. Even though the stack-based Thread object is
    lost, the thread itself lives on until its associated task
    completes. Although this may be counterintuitive from a C++
    standpoint, the concept of threads is a departure from the norm: a
    thread creates a separate thread of execution that persists after the
    function call ends. This departure is reflected in the persistence of
    the underlying thread after the object vanishes.
    -->
    <para>
      El bucle for puede parecer un poco extraño a priori ya que se
      crea localmente dentro del bucle for e inmediatamente después
      sale del ámbito y es destruído. Esto hace que parezca que el
      hilo propiamente dicho pueda perderse inmediatamente, pero puede
      ver por la salida que los hilos, en efecto, están en ejecución
      hasta su finalización. Cuando crea un
      objeto <classname>Thread</classname>, el hilo asociado se
      registra en el sistema de hilos, que lo mantiene vivo. A pesar
      de que el objeto <classname>Thread</classname> local se pierde,
      el hilo sigue vivo hasta que su tarea asociada termina. Aunque
      puede ser poco intuitivo desde el punto de vista de C++, el
      concepto de hilos es la excepción de la regla: un hilo crea un
      hilo de ejecución separado que persiste después de que la
      llamada a función finalice. Esta excepción se refleja en la
      persistencia del hilo subyacente después de que el objeto
      desaparezca.
    </para>

    <sect2>
      <!-- : Creating responsive user interfaces -->
      <title>Creación de interfaces de usuarios interactivas</title>

      <!--
      As stated earlier, one of the motivations for using threading is to
      create a responsive user interface. Although we don?t cover graphical
      user interfaces in this book, you can still see a simple example of a
      console-based user interface.
      -->
      <para>
	Como se dijo anteriormente, uno de las motivaciones para usar
	hilos es crear interfaces de usuario interactivas. Aunque en
	este libro no cubriremos las interfaces gráficas de usuario,
	verá un ejemplo sencillo de una interfaz de usuario basada en
	consola.
      </para>

      <!--
      The following example reads lines from a file and prints them to the
      console, sleeping (suspending the current thread) for a second after
      each line is displayed. (You?ll learn more about sleeping later in the
      chapter.) During this process, the program doesn?t look for user
      input, so the UI is unresponsive:
      -->
      <para>
	El siguiente ejemplo lee líneas de un archivo y las imprime a
	la consola, durmiéndose (suspender el hilo actual) durante un
	segundo después de que cada línea sea mostrada. (Aprenderá más
	sobre el proceso de dormir hilos en el capítulo.) Durante este
	proceso, el programa no busca la entrada del usuario, por lo
	que la IU no es interactiva:
      </para>


//: V2C11:UnresponsiveUI.cpp


      <!--
      To make the program responsive, you can execute a task that displays
      the file in a separate thread. The main thread can then watch for user
      input so the program becomes responsive:
      -->
      <para>
	Para hacer este programa interactivo, puede ejecutar una tarea
	que muestre el archivo en un hilo separado. De esta forma, el
	hilo principal puede leer la entrada del usuario, por lo que
	el programa se vuelve interactivo:
      </para>


//: V2C11:ResponsiveUI.cpp


      <!--
      Now the main( ) thread can respond immediately when you press <Return>
      and call quit( ) on the DisplayTask.
      -->
      <para>
	Ahora el hilo main() puede responder inmediatamente cuando
	pulse Return e invocar quit()
	sobre <classname>DisplayTask</classname>.
      </para>

      <!--
      This example also shows the need for communication between tasks?the
      task in the main( ) thread needs to tell the DisplayTask to shut
      down. Since we have a pointer to the DisplayTask, you might think of
      just calling delete on that pointer to kill the task, but this
      produces unreliable programs. The problem is that the task could be in
      the middle of something important when you destroy it, and so you are
      likely to put the program in an unstable state. Here, the task itself
      decides when it?s safe to shut down. The easiest way to do this is by
      simply notifying the task that you?d like it to stop by setting a
      Boolean flag. When the task gets to a stable point it can check that
      flag and do whatever is necessary to clean up before returning from
      run( ). When the task returns from run( ), the Thread knows that the
      task has completed.
      -->
      <para>
	Este ejemplo también muestra la necesidad de una comunicación
	entre tareas - la tarea en el hilo main() necesita parar
	al <classname>DisplayTask</classname>. Dado que tenemos un
	puntero a DisplayTask, puede pensar que bastaría con llamar al
	destructor de ese puntero para matar la tarea, pero esto hace
	que los programas sean poco fiables. El problema es que la
	tarea podría estar en mitad de algo importante cuando lo
	destruye y, por lo tanto, es probable que ponga el programa en
	un estado inestable. En este sentido, la propia tarea decide
	cuando es seguro terminar. La manera más sencilla de hacer
	esto es simplemente notificar a la tarea que desea detener
	mediante una bandera booleana. Cuando la tarea se encuentre en
	un punto estable puede consultar esa bandera y hacer lo que
	sea necesario para limpiar el estado después de regresar de
	run(). Cuando la tarea vuelve de
	run(), <classname>Thread</classname> sabe que la tarea se ha
	completado.
      </para>

      <!--
      Although this program is simple enough that it should not have any
      problems, there are some small flaws regarding inter-task
      communication. This is an important topic that will be covered later
      in this chapter.
      -->
      <para>
	Aunque este programa es lo suficientemente simple para que no
	haya problemas, hay algunos pequeños defectos respecto a la
	comunicación entre pilas. Es un tema importante que se cubrirá
	más tarde en este capítulo.
      </para>

    </sect2>
    <sect2>
      <!-- Simplifying with Executors -->
      <title>Simplificación con Ejecutores</title>
      
      <!--
      You can simplify your coding overhead by using ZThread
      Executors. Executors provide a layer of indirection between a client
      and the execution of a task; instead of a client executing a task
      directly, an intermediate object executes the task.
      -->
      <para>
	Utilizando los Ejecutores de ZThread, puede simplificar su
	código. Los Ejecutores proporcionan una capa de indirección
	entre un cliente y la ejecución de una tarea; a diferencia de
	un cliente que ejecuta una tarea directamente, un objeto
	intermediario ejecuta la tarea. 
      </para>

      <!--
      We can show this by using an Executor instead of explicitly creating
      Thread objects in MoreBasicThreads.cpp. A LiftOff object knows how to
      run a specific task; like the Command Pattern, it exposes a single
      function to be executed. An Executor object knows how build the
      appropriate context to execute Runnable objects. In the following
      example, the ThreadedExecutor creates one thread per task:
      -->
      <para>
	Podemos verlo utilizando un Ejecutor en vez de la creación
	explícita de objetos <classname>Thread</classname> en
	MoreBasicThreads.cpp. Un objeto <classname>LiftOff</classname>
	conoce cómo ejecutar una tarea específica; como el patrón
	Command, expone una única función a ejecutar. Un
	objeto <classname>Executor</classname> conoce como construir
	el contexto apropiado para lanzar
	objetos <classname>Runnable</classname>. En el siguiente
	ejemplo, <classname>ThreadedExecutor</classname> crea un hilo
	por tarea:
      </para>


//: V2C11:ThreadedExecutor.cpp


      <!--
      Note that in some cases a single Executor can be used to create and
      manage all the threads in your system. You must still place the
      threading code inside a try block because an Executor?s execute( )
      function may throw a Synchronization_Exception if something goes
      wrong. This is true for any function that involves changing the state
      of a synchronization object (starting threads, acquiring mutexes,
      waiting on conditions, etc.), as you will learn later in this chapter.
      -->
      <para>
	Note que algunos casos un <classname>Executor</classname>
	individual puede ser usado para crear y gestionar todo los
	hilos en su sistema. Debe colocar el código correspondiente a
	los hilos dentro de un bloque try porque el método execute()
	de un <classname>Executor</classname> puede lanzar una
	<classname>Synchronization_Exception</classname> si algo va
	mal. Esto es válido para cualquier función que implique
	cambiar el estado de un objeto de sincronización (arranque de
	hilos, la adquisición de mutexes, esperas en condiciones,
	etc.), tal y como aprenderá más adelante en este capítulo. 
      </para>

      <!--
      The program will exit as soon as all the tasks in the Executor
      complete.
      -->
      <para>
	El programa finalizará cuando todas las tareas en
	el <classname>Executor</classname> hayan concluido.
      </para>

      <!--
      In the previous example, the ThreadedExecutor creates a thread for
      each task that you want to run, but you can easily change the way
      these tasks are executed by replacing the ThreadedExecutor with a
      different type of Executor. In this chapter, using a ThreadedExecutor
      is fine, but in production code it might result in excessive costs
      from the creation of too many threads. In that case, you can replace
      it with a PoolExecutor, which will use a limited set of threads to
      execute the submitted tasks in parallel:
      -->
      <para>
	En el siguiente
	ejemplo, <classname>ThreadedExecutor</classname> crea un hilo
	para cada tarea que quiera ejecutar, pero puede cambiar
	fácilmente la forma en la que esas tareas son ejecutadas
	reemplazando el <classname>ThreadedExecutor</classname> por un
	tipo diferente de <classname>Executor</classname>. En este
	capítulo, usar un <classname>ThreadedExecutor</classname> está
	bien, pero para código en producción puede resultar
	excesivamente costoso para la creación de muchos hilos. En ese
	caso, puede reemplazarlo por
	un <classname>PoolExecutor</classname>, que utilizará un
	conjunto limitado de hilos para lanzar las tareas registradas
	en paralelo:
      </para>


//: V2C11:PoolExecutor.cpp


      <!--
      With the PoolExecutor, you do expensive thread allocation once, up
      front, and the threads are reused when possible. This saves time
      because you aren?t constantly paying for thread creation overhead for
      every single task. Also, in an event-driven system, events that
      require threads to handle them can be generated as quickly as you want
      by simply fetching them from the pool. You don?t overrun the available
      resources because the PoolExecutor uses a bounded number of Thread
      objects. Thus, although this book will use ThreadedExecutors, consider
      using PoolExecutors in production code.
      -->
      <para>
	Con <classname>PoolExecutor</classname> puede realizar una
	asignación inicial de hilos costosa de una sola vez, por
	adelantado, y los hilos se reutilizan cuando sea posible. Esto
	ahorra tiempo porque no está pagando el gasto de la creación
	de hilos por cada tarea individual de forma constante. Además,
	en un sistema dirigido por eventos, los eventos que requieren
	hilos para manejarlos puede ser generados tan rápido como
	quiera, basta con traerlos del pool. No excederá los recursos
	disponibles porque <classname>PoolExecutor</classname> utiliza
	un número limitado de
	objetos <classname>Thread</classname>. Así, aunque en este
	libro se utilizará <classname>ThreadedExecutors</classname>,
	tenga en cuenta utilizar <classname>PoolExecutor</classname>
	para código en producción. 
      </para>

      <!--
      A ConcurrentExecutor is like a PoolExecutor with a fixed size of one
      thread. This is useful for anything you want to run in another thread
      continually (a long-lived task), such as a task that listens to
      incoming socket connections. It is also handy for short tasks that you
      want to run in a thread, for example, small tasks that update a local
      or remote log, or for an event-dispatching thread.
      -->
      <para>
	<classname>ConcurrentExecutor</classname> es
	como <classname>PoolExecutor</classname> pero con un tamaño
	fijo de hilos. Es útil para cualquier cosa que quiera lanzar
	en otro hilo de forma continua (una tarea de larga duración),
	como una tare que escucha conexiones entrantes en un
	socket. También es útil para tareas cortas que quiera lanzar
	en un hilo, por ejemplo, pequeñas tareas que actualizar un log
	local o remoto, o para un hilo que atienda a eventos. 
      </para>

      <!--
      If more than one task is submitted to a ConcurrentExecutor, each task
      will run to completion before the next task is begun, all using the
      same thread. In the following example, you?ll see each task completed,
      in the order that it was submitted, before the next one is
      begun. Thus, a ConcurrentExecutor serializes the tasks that are
      submitted to it.
      -->
      <para>
	Si hay más de una tarea registrada en
	un <classname>ConcurrentExecutor</classname>, cada una de
	ellas se ejecutará completamente hasta que la siguiente
	empiece; todas utilizando el mismo hilo. En el ejemplo
	siguiente, verá que cada tarea se completa, en el orden en el
	que fue registrada, antes de que la siguiente comience. De
	esta forma, un <classname>ConcurrentExecutor</classname>
	serializa las tareas que le fueron asignadas.
      </para>


//: V2C11:ConcurrentExecutor.cpp


      <!--
      Like a ConcurrentExecutor, a SynchronousExecutor is used when you want
      only one task at a time to run, serially instead of
      concurrently. Unlike ConcurrentExecutor, a SynchronousExecutor doesn?
      t create or manage threads on it own. It uses the thread that submits
      the task and thus only acts as a focal point for synchronization. If
      you have n threads submitting tasks to a SynchronousExecutor, no two
      tasks are ever run at once. Instead, each one is run to completion,
      then the next one in the queue is begun.
      -->
      <para>
	Como un <classname>ConcurrentExecutor</classname>,
	un <classname>SynchronousExecutor</classname> se usa cuando
	quiera una única tarea se ejecute al mismo tiempo, en serie en
	lugar de concurrente. A diferencia
	de <classname>ConcurrentExecutor</classname>,
	un <classname>SynchronousExecutor</classname> no crea ni
	gestiona hilos sobre si mismo. Utiliza el hilo que añadió la
	tarea y, así, únicamente actúa como un punto focal para la
	sincronización. Si tiene n tareas registradas en
	un <classname>SynchronousExecutor</classname>, nunca habrá 2
	tareas que se ejecuten a la vez. En lugar de eso, cada una se
	ejecutará hasta su finalización y la siguiente en la cola
	comenzará. 
      </para>

      <!--
      For example, suppose you have a number of threads running tasks that
      use the file system, but you are writing portable code so you don?t
      want to use flock( ) or another OS-specific call to lock a file. You
      can run these tasks with a SynchronousExecutor to ensure that only one
      task at a time is running from any thread. This way, you don?t need to
      deal with synchronizing on the shared resource (and you won?t clobber
      the file system in the meantime). A better solution is to synchronize
      on the resource (which you?ll learn about later in this chapter), but
      a SynchronousExecutor lets you skip the trouble of getting coordinated
      properly just to prototype something.
      -->
      <para>
	Por ejemplo, suponga que tiene un número de hilos ejecutando
	tareas que usan un sistema de archivos, pero está escribiendo
	código portable luego no quiere utilizar flock() u otra
	llamada al sistema operativo específica para bloquear un
	archivo. Puede lanzar esas tareas con
	un <classname>SynchronousExecutor</classname> para asegurar
	que solamente una de ellas, en un tiempo determinado, está
	ejecutándose desde cualquier hilo. De esta manera, no necesita
	preocuparse por la sincronización del recurso compartido (y,
	de paso, no se cargará el sistema de archivos). Una mejor
	solución pasa por sincronizar el recurso (lo cual aprenderá
	más adelante en este capítulo), sin embargo
	un <classname>SynchronousExecutor</classname> le permite
	evitar las molestias de obtener una coordinación adecuada para
	prototipar algo.
      </para>


//: V2C11:SynchronousExecutor.cpp


      <!--
      When you run the program, you?ll see that the tasks are executed in
      the order they are submitted, and each task runs to completion before
      the next one starts. What you don?t see is that no new threads are
      created?the main( ) thread is used for each task, since in this
      example, that?s the thread that submits all the tasks. Because
      SynchronousExecutor is primarily for prototyping, you may not use it
      much in production code.
      -->
      <para>
	Cuando ejecuta el programa verá que las tareas son lanzadas en
	el orden en el que fueron registradas, y cada tarea se ejecuta
	completamente antes de que la siguiente empiece. ¿Qué es lo
	que no ve y que hace que no se creen nuevos hilos? El hilo
	main() se usa para cada tarea, y debido a este ejemplo, ese es
	el hilo que registra todas las tareas. Podría no utilizar 
	un <classname>SynchronousExecutor</classname> en código en 
	producción porque, principalmente, es para prototipado.
      </para>

    </sect2>
    <sect2>
      <!-- : Yielding -->
      <title>Ceder el paso</title>

      <!--
      If you know that you?ve accomplished what you need to during one pass
      through a loop in your run( ) function (most run( ) functions involve
      a long-running loop), you can give a hint to the thread scheduling
      mechanism that you?ve done enough and that some other thread might as
      well have the CPU. This hint (and it is a hint?there?s no guarantee
      your implementation will listen to it) takes the form of the yield( )
      function.
      -->
      <para>
	Si sabe que ha logrado realizar lo que necesita durante una
	pasada a través de un bucle en su función run() (la mayoría de
	las funciones run() suponen un periodo largo de tiempo de
	ejecución), puede darle un toque al mecanismo de planificación
	de hilos, decirle que ya ha hecho suficiente y que algún otro
	hilo puede tener la CPU. Este toque (y es un toque - no hay
	garantía de que su implementación vaya a escucharlo) adopta la
	forma de la función yield().
      </para>

      <!--
      We can make a modified version of the LiftOff examples by yielding
      after each loop:
      -->
      <para>
	Podemos construir una versión modificada
	de los ejemplos de <classname>LiftOff</classname> cediendo el
	paso después de cada bucle:
      </para>


//: V2C11:YieldingTask.cpp


      <!--
      You can see that the task?s run( ) member function consists entirely
      of an infinite loop. By using yield( ), the output is evened up quite
      a bit over that without yielding. Try commenting out the call to
      Thread::yield( ) to see the difference. In general, however, yield( )
      is useful only in rare situations, and you can?t rely on it to do any
      serious tuning of your application.
      -->
      <para>
	Puede ver que la tarea del método run() es en un bucle
	infinito en su totalidad. Utilizando yield( ), la salida se
	equilibra bastante que en el caso en el que no se cede el
	paso. Pruebe a comentar la llamada a Thread::yield() para ver
	la diferencia. Sin embargo, en general, yield() es útil en
	raras ocasiones, y no puede contar con ella para realizar un
	afinamiento serio sobre su aplicación.
      </para>

    </sect2>
    <sect2>
      <!-- : Sleeping -->
      <title>Dormido</title>

      <!--
      Another way you can control the behavior of your threads is by calling
      sleep( ) to cease execution of a thread for a given number of
      milliseconds. In the preceding example, if you replace the call to
      yield( ) with a call to sleep( ), you get the following:
      -->
      <para>
	Otra forma con la que puede tener control sobre el
	comportamiento de su hilos es llamando a sleep() para cesar la
	ejecución de uno de ellos durante un número de milisegundos
	dado. En el ejemplo que viene a continuación, si cambia la llamada a
	yield() por una a sleep(), obtendrá lo siguiente:
      </para>


//: V2C11:SleepingTask.cpp


      <!--
      Thread::sleep( ) can throw an Interrupted_Exception (you?ll learn
      about interrupts later), and you can see that this is caught in run(
      ). But the task is created and executed inside a try block in main( )
      that catches Synchronization_Exception (the base class for all ZThread
      exceptions), so wouldn?t it be possible to just ignore the exception
      in run( ) and assume that it will propagate to the handler in main( )?
      This won?t work because exceptions won?t propagate across threads back
      to main( ). Thus, you must handle any exceptions locally that may
      arise within a task.
      -->
      <para>
	Thread::sleep() puede lanzar
	una <classname>Interrupted_Exception</classname>(sobre las
	interrupciones aprenderá más adelante), y puede ver que esta
	excepción se captura en run(). Sin embargo, la tarea se crea y
	se ejecuta dentro de un bloque try en main() que
	captura <classname>Interrupted_Exception</classname> (la clase
	base para todas las excepciones de ZThread), por lo que ¿no
	sería posible ignorar la excepción en run() y asumir que se
	propagará al manejador en main()?. Esto no funcionará porque
	las excepciones no se propagarán a lo largo de los hilos para
	volver hacia main(). De esta forma, debe manejar cualquier
	excepción que pueda ocurrir dentro de una tarea de forma
	local.
      </para>

      <!--
      You?ll notice that the threads tend to run in any order, which means
      that sleep( ) is also not a way for you to control the order of thread
      execution. It just stops the execution of the thread for awhile. The
      only guarantee that you have is that the thread will sleep at least
      100 milliseconds (in this example), but it may take longer before the
      thread resumes execution because the thread scheduler still has to get
      back to it after the sleep interval expires.
      -->
      <para>
	Notará que los hilos tienden a ejecutarse en cualquier orden,
	lo que quiere decir que sleep() tampoco es una forma de
	controlar el orden de la ejecución de los hilos. Simplemente
	para la ejecución del hilo durante un rato. La única garantía
	que tiene es que el hilo se dormirá durante, al menos, 100
	milisegundos (en este ejemplo), pero puede que tarde más
	después de que el hilo reinicie la ejecución ya que el
	planificador de hilos tiene que volver a él tras haber
	expirado el intervalo.
      </para>

      <!--
      If you must control the order of execution of threads, your best bet
      is to use synchronization controls (described later) or, in some
      cases, not to use threads at all, but instead to write your own
      cooperative routines that hand control to each other in a specified
      order.
      -->
      <para>
	Si debe tener control sobre el orden de la ejecución de hilos,
	su mejor baza es el uso de controles de sincronización
	(descritos más adelante) o, en algunos casos, no usar hilos en
	todo, FIXMEbut instead to write your own cooperative routines that
	hand control to each other in a specified order.
      </para>

    </sect2>
    <sect2>
      <!-- : Priority -->
      <title>Prioridad</title>

      <!--
      The priority of a thread conveys the importance of a thread to the
      scheduler. Although the order that the CPU runs a set of threads is
      indeterminate, the scheduler will lean toward running the waiting
      thread with the highest priority first. However, this doesn?t mean
      that threads with lower priority aren?t run (that is, you can?t get
      deadlocked because of priorities). Lower priority threads just tend to
      run less often.
      -->
      <para>
	La prioridad de un hilo representa la importancia de ese hilo
	para el planificador. Pese a que el orden en que la CPU
	ejecuta un conjunto de hilos es indeterminado, el planificador
	tenderá a ejecutar el hilo con mayor prioridad de los que
	estén esperando. Sin embargo, no quiere decir que hilos con
	menos prioridad no se ejecutarán (es decir, no tendrá bloqueo
	de un hilo a causa de las prioridades). Simplemente, los hilos
	con menos prioridad tenderán a ejecutarse menos frecuentemente.
      </para>

      <!--
      Here?s MoreBasicThreads.cpp modified so that the priority levels are
      demonstrated. The priorities are adjusting by using Thread?s
      setPriority( ) function.
      -->
      <para>
	Se ha modificado MoreBasicThreads.cpp para mostrar los niveles
	de prioridad. Las prioridades se ajustan utilizando la función
	setPriority() de <classname>Thread</classname>.
      </para>


//: V2C11:SimplePriorities.cpp


      <!--
      Here, operator<<( ) is overridden to display the identifier, priority,
      and countDown value of the task.
      -->
      <para>
	En este ejemplo, el operador <<() se sobreescribe para mostrar
	el identificador, la prioridad y el valor de countDown de la
	tarea.
      </para>

      <!--
      You can see that the priority level of thread high is at the highest
      level, and all the rest of the threads are at the lowest level. We are
      not using an Executor in this example because we need direct access to
      the threads in order to set their priorities.
      -->
      <para>
	Puede ver que el nivel de prioridad del hilo es el más alto, y
	que el resto de hilos tienen el nivel más bajo. No
	utilizamos <classname>Executor</classname> en este ejemplo
	porque necesitamos acceder directamente al hilo para
	configurar sus propiedades.
      </para>

      <!--
      Inside SimplePriorities::run( ), 100,000 repetitions of a rather
      expensive floating-point calculation are performed, involving double
      addition and division. The variable d is volatile to try to ensure
      that no compilers optimizations are performed. Without this
      calculation, you don?t see the effect of setting the priority
      levels. (Try it: comment out the for loop containing the double
      calculations.) With the calculation, you see that thread high is given
      a higher preference by the thread scheduler. (At least, this was the
      behavior on a Windows machine.) The calculation takes long enough that
      the thread scheduling mechanism jumps in, changes threads, and pays
      attention to the priorities so that thread high gets preference.
      -->
      <para>
	Dentro de SimplePriorities::run() se ejecutan 100,000 veces un
	costoso conjunto de cálculos en punto flotante. La variable d
	es volátil para intentar garantizar que ningún compilador hace
	optimizaciones. Sin este cálculo, no comprobará el efecto de
	la configuración de los niveles de prioridad. (Pruébelo:
	comente el bucle for que contiene los cálculos en doble
	precisión.) Con el cálculo puede ver que el planificador de
	hilos al hilo high se le da más preferencia. (Al menos, este
	fue el comportamiento sobre una máquina Windows). El cálculo
	tarda lo suficiente para que el mecanismo de planificación de
	hilos lo salte, cambie hilos y tome en cuenta las prioridades
	para que el hilo high tenga preferencia.
      </para>

      <!--
      You can also read the priority of an existing thread with getPriority(
      ) and change it at any time (not just before the thread is run, as in
      SimplePriorities.cpp) with setPriority( ).
      -->
      <para>
	También, puede leer la prioridad de un hilo existente con
	getPriority() y cambiarla en cualquier momento (no sólo antes
	de que el hilo se ejecute, como en SimplePriorities.cpp) con
	setPriority().
      </para>

      <!-- Mapping priorities to operating systems is problematic. For
      example, Windows 2000 has seven priority levels, while Sun?s
      Solaris has 231 levels. The only portable approach is to stick
      to very large priority granulations, such as the Low, Medium,
      and High used in the ZThread library.  -->
      <para>
	La correspondencia de las prioridades con el sistema operativo
	es un problema. Por ejemplo, Windows 2000 tiene siete niveles
	de prioridades, mientras que Solaris de Sun tiene 231. El
	único enfoque portable es ceñirse a los niveles discretos de
	prioridad, como Low, Medium y High utilizados en la librería
	ZThread.
      </para>

    </sect2>
  </sect1>
  <sect1>
    <!-- : Sharing limited resources -->
    <title>Comparición de recursos limitados</title>

    <!--
    You can think of a single-threaded program as one lonely entity moving
    around through your problem space and doing one thing at a
    time. Because there?s only one entity, you never have to think about
    the problem of two entities trying to use the same resource at the
    same time: problems such as two people trying to park in the same
    space, walk through a door at the same time, or even talk at the same
    time.
    -->
    <para>
      Piense en un programa con un único hilo como una solitaria
      entidad moviéndose a lo largo del espacio de su problema y
      haciendo una cosa en cada instante. Debido a que sólo hay una
      entidad, no tiene que preocuparse por el problema de dos
      entidades intentando usar el mismo recurso al mismo tiempo:
      problemas como dos personas intentando aparcar en el mismo
      sitio, pasar por una puerta al mismo tiempo o incluso hablar al
      mismo tiempo. 
    </para>

    <!--
    With multithreading things aren?t lonely anymore, but you now have the
    possibility of two or more threads trying to use the same resource at
    once. This can cause two different kinds of problems. The first is
    that the necessary resources may not exist. In C++, the programmer has
    complete control over the lifetime of objects, and it?s easy to create
    threads that try to use objects that get destroyed before those
    threads complete.
    -->
    <para>
      Con multihilado las cosas ya no son solitarias, pero ahora tiene
      la posibilidad de tener dos o más hilos intentando utilizar un
      mismo recurso a la vez. Esto puede causar dos problemas
      distintos. El primero es que el recurso necesario podría no
      existir. En C++, el programador tiene un control total sobre la
      vida de los objetos, y es fácil crear hilos que intenten usar
      objetos que han sido destruidos antes de que esos hilos hayan
      finalizado.
    </para>

    <!--
    The second problem is that two or more threads may collide when they
    try to access the same resource at the same time. If you don?t prevent
    such a collision, you?ll have two threads trying to access the same
    bank account at the same time, print to the same printer, adjust the
    same valve, and so on.
    -->
    <para>
      El segundo problema es que dos o más hilos podrían chocar cuando
      intenten acceder al mismo dispositivo al mismo tiempo. Si no
      previene esta colisión, tendrá dos hilos intentando acceder a la
      misma cuenta bancaria al mismo tiempo, imprimir en la misma
      impresora, ajustar la misma válvula, etc.
    </para>

    <!--
    This section introduces the problem of objects that vanish while tasks
    are still using them and the problem of tasks colliding over shared
    resources. You?ll learn about the tools that are used to solve these
    problems.
    -->
    <para>
      Esta sección presenta el problema de los objetos que desaparecen
      mientras las tareas aún están usándolos y el problema del choque
      entre tareas sobre recursos compartidos. Aprenderá sobre las
      herramientas que se usan para solucionar esos problemas.
    </para>

    <sect2>
      <!-- : Ensuring the existence of objects -->
      <title>Aseguramiento de la existencia de objetos</title>

      <!--
      Memory and resource management are major concerns in C++. When you
      create any C++ program, you have the option of creating objects on the
      stack or on the heap (using new). In a single-threaded program, it?s
      usually easy to keep track of object lifetimes so that you don?t try
      to use objects that are already destroyed.
      -->
      <para>
	La gestión de memoria y recursos son las principales
	preocupaciones en C++. Cuando crea cualquier programa en C++,
	tiene la opción de crear objetos en la pila o en el heap
	(utilizando new). En un programa con un solo hilo, normalmente
	es sencillo seguir la vida de los objetos con el fin de que no
	tenga que utilizar objetos que ya están destruidos.
      </para>

      <!--
      The examples shown in this chapter create Runnable objects on the heap
      using new, but you?ll notice that these objects are never explicitly
      deleted. However, you can see from the output when you run the
      programs that the thread library keeps track of each task and
      eventually deletes it, because the destructors for the tasks are
      called. This happens when the Runnable::run( ) member function
      completes?returning from run( ) indicates that the task is finished.
      -->
      <para>
	Los ejemplos mostrados en este capítulo crean
	objetos <classname>Runnable</classname> en el heap utilizando
	new, se dará cuenta que esos objetos nunca son destruidos
	explícitamente. Sin embargo, podrá por la salida cuando
	ejecuta el programa que la biblioteca de hilos sigue la pista
	a cada tarea y, eventualmente, las destruye. Esto ocurre
	cuando el método Runnable::run() finaliza - volver de run()
	indica que la tarea ha finalizado.
      </para>

      <!--
      Burdening the thread with deleting a task is a problem. That thread
      doesn?t necessarily know if another thread still needs to make a
      reference to that Runnable, and so the Runnable may be prematurely
      destroyed. To deal with this problem, tasks in ZThreads are
      automatically reference-counted by the ZThread library mechanism. A
      task is maintained until the reference count for that task goes to
      zero, at which point the task is deleted. This means that tasks must
      always be deleted dynamically, and so they cannot be created on the
      stack. Instead, tasks must always be created using new, as you see in
      all the examples in this chapter.
      -->
      <para>
	Recargar el hilo al destruir una tarea es un problema. Ese
	hilo sabe necesariamente si otro necesita hacer referencia a
	ese Runnable, y por ello el Runnable podría ser destruido
	prematuramente. Para ocuparse de este problema, el mecanismo
	de la biblioteca ZThread mantiene un conteo de referencias
	sobre las tareas. Una tarea se mantiene viva hasta que su
	contador de referencias se pone a cero, en este punto la tarea
	se destruye. Esto quiere decir que las tareas tienen que ser
	destruidas dinámicamente siempre, por lo que no pueden ser
	creadas en la pila. En vez de eso, las tareas deben ser
	creadas utilizando new, tal y como puede ver en todos los
	ejemplos de este capítulo.  tareas in ZThreads
      </para>

      <!--
      Often you must also ensure that non-task objects stay alive as long as
      tasks need them. Otherwise, it?s easy for objects that are used by
      tasks to go out of scope before those tasks are completed. If this
      happens, the tasks will try to access illegal storage and will cause
      program faults. Here?s a simple example:
      -->
      <para>
	Además, también debe asegurar que los objetos que no son
	tareas estarán vivos tanto tiempo como el que las tareas
	necesiten de ellos. Por otro lado, resulta sencillo para los
	objetos utilizados por las tareas salir del ámbito antes de
	que las tareas hayan concluido. Si ocurre esto, las tareas
	intentarán acceder zonas de almacenamiento ilegales y
	provocará que el programa falle. He aquí un simple ejemplo:
      </para>


//: V2C11:Incrementer.cpp


      <!--
      The Count class may seem like overkill at first, but if n is only a
      single int (rather than an array), the compiler can put it into a
      register and that storage will still be available (albeit technically
      illegal) after the Count object goes out of scope. It?s difficult to
      detect the memory violation in that case. Your results may vary
      depending on your compiler and operating system, but try making it n a
      single int and see what happens. In any event, if Count contains an
      array of ints as above, the compiler is forced to put it on the stack
      and not in a register.
      -->
      <para>
	Podría parecer a priori que la
	clase <classname>Count</classname> es excesiva, pero si
	únicamente n es un int (en lugar de una matriz), el compilador
	puede ponerlo dentro de un registro y ese almacenamiento
	seguirá estando disponible (aunque técnicamente es ilegal)
	después de que el objeto <classname>Count</classname> salga
	del ámbito. Es difícil detectar la violación de memoria en
	este caso. Sus resultados podrían variar dependiendo de su
	compilador y de su sistema operativo, pero pruebe a que n sea
	un int y verá qué ocurre. En cualquier evento,
	si <classname>Count</classname> contiene una matriz de ints y
	como antes, el compilador está obligado a ponerlo en la pila y
	no en un registro. 
      </para>

      <!--
      Incrementer is a simple task that uses a Count object. In main( ), you
      can see that the Incrementer tasks are running for long enough that
      the Count object will go out of scope, and so the tasks try to access
      an object that no longer exists. This produces a program fault.
      -->
      <para>
	<classname>Incrementer</classname> es una tarea sencilla que
	utiliza un objeto <classname>Count</classname>. En main(),
	puede ver que las tareas <classname>Incrementer</classname> se
	ejecutan el tiempo suficiente para que el salga del ámbito,
	por lo que la tarea intentará acceder a un objeto que no
	existe. Esto produce un fallo en el programa.
	objeto <classname>Count</classname> 
      </para>

      <!--
      To fix the problem, we must guarantee that any objects shared between
      tasks will be around as long as those tasks need them. (If the objects
      were not shared, they could be composed directly into the task?s class
      and thus tie their lifetime to that task.) Since we don?t want the
      static program scope to control the lifetime of the object, we put the
      object on the heap. And to make sure that the object is not destroyed
      until there are no other objects (tasks, in this case) using it, we
      use reference counting.
      -->
      <para>
	Para solucionar este problema, debemos garantizar que
	cualquiera de los objetos compartidos entre tareas estarán
	accesibles tanto tiempo como las tareas los necesiten. (Si los
	objetos no fueran compartidos, podrían estar directamente
	dentro de las clases de las tareas y, así, unir su tiempo de
	vida a la tarea.) Dado que no queremos que el propio ámbito
	estático del programa controle el tiempo de vida del objeto,
	pondremos el en heap. Y para asegurar que el objeto no se
	destruye hasta que no haya objetos (tareas, en este caso) que
	lo estén utilizando, utilizaremos el conteo de referencias.
      </para>

      <!--
      Reference counting was explained thoroughly in volume one of this book
      and further revisited in this volume. The ZThread library includes a
      template called CountedPtr that automatically performs reference
      counting and deletes an object when the reference count goes to
      zero. Here?s the above program modified to use CountedPtr to prevent
      the fault:
      -->
      <para>
	El conteo de referencias se ha explicado a lo largo del
	volumen uno de este libro y además se revisará en este
	volumen. La librería ZThread incluye una plantilla
	llamada <classname>CountedPtr</classname> que automáticamente
	realiza el conteo de referencias y destruye un objeto cuando
	su contador de referencias vale cero. A continuación, se ha
	modificado el programa para que
	utilice <classname>CountedPtr</classname> para evitar el
	fallo:
      </para>


//: V2C11:ReferenceCounting.cpp


      <!--
      Incrementer now contains a CountedPtr object, which manages a
      Count. In main( ), the CountedPtr objects are passed into the two
      Incrementer objects by value, so the copy-constructor is called,
      increasing the reference count. As long as the tasks are still
      running, the reference count will be nonzero, and so the Count object
      managed by the CountedPtr will not be destroyed. Only when all the
      tasks using the Count are completed will delete be called
      (automatically) on the Count object by the CountedPtr.
      -->
      <para>
	Ahora <classname>Incrementer</classname> contiene un
	objeto <classname>CountedPtr</classname>, que gestiona
	un <classname>Count</classname>. En la función main(), los
	objetos <classname>CountedPtr</classname> se pasan a los dos
	objetos <classname>Incrementer</classname> por valor, por lo
	que se llama el constructor de copia, incrementando el
	conteo de referencias. Mientras la tarea esté ejecutándose, el
	contador de referencias no valdrá cero, por lo que el
	objeto <classname>Count</classname> utilizado
	por <classname>CountedPtr</classname> no será
	destruído. Solamente cuando todas las tareas que utilice
	el <classname>Count</classname> terminen se llamará al
	destructor (automáticamente) sobre el
	objeto <classname>Count</classname> por
	el <classname>CountedPtr</classname>.
     </para>

      <!--
      Whenever you have objects that are used by more than one task, you?ll
      almost always need to manage those objects using the CountedPtr
      template in order to prevent problems arising from object lifetime
      issues.
      -->
      <para>
	Siempre que tenga una tarea que utilice más de un objeto, casi
	siempre necesitará controlar aquellos objetos utilizando la
	plantilla <classname>CountedPtr</classname> para evitar
	problemas derivados del tiempo de vida de los objetos. 
      </para>

    </sect2>
    <sect2>
      <!-- : Improperly accessing resources -->
      <title>Acceso no apropiado a recursos</title>

      <!--
      Consider the following example where one task generates even numbers
      and other tasks consume those numbers. Here, the only job of the
      consumer threads is to check the validity of the even numbers.
      -->
      <para>
	Considere el siguiente ejemplo, donde una tarea genera números
	constantes y otras tareas consumen esos números. Ahora, el
	único trabajo de los hilos consumidores es probar la validez
	de los números constantes.
      </para>

      <!--
      We?ll first define EvenChecker, the consumer thread, since it will be
      reused in all the subsequent examples. To decouple EvenChecker from
      the various types of generators that we will experiment with, we?ll
      create an interface called Generator, which contains the minimum
      necessary functions that EvenChecker must know about: that it has a
      nextValue( ) function and that it can be canceled.
      -->
      <para>
	Primeramente, definiremos <classname>EvenChecker</classname>,
	el hilo consumidor, puesto que será reutilizado en todos los
	ejemplos siguientes. Para
	desacoplar <classname>EvenChecker</classname> de los varios
	tipos de generadores con los que experimentaremos, crearemos
	una interfaz llamada <classname>Generator</classname> que
	contiene el número mínimo de funciones
	que <classname>EvenChecker</classname> necesita conocer: por
	lo que tiene una función nextValue() y que puede ser
	cancelada.
      </para>


//: V2C11:EvenChecker.h


      <!--
      The Generator class introduces the abstract Cancelable class, which is
      part of the ZThread library. The goal of Cancelable is to provide a
      consistent interface to change the state of an object via the cancel(
      ) function and to see whether the object has been canceled with the
      isCanceled( ) function. Here, we use the simple approach of a bool
      canceled flag, similar to the quitFlag previously seen in
      ResponsiveUI.cpp. Note that in this example the class that is
      Cancelable is not Runnable. Instead, all the EvenChecker tasks that
      depend on the Cancelable object (the Generator) test it to see if it?
      s been canceled, as you can see in run( ). This way, the tasks that
      share the common resource (the Cancelable Generator) watch that
      resource for the signal to terminate. This eliminates the so-called
      race condition, where two or more tasks race to respond to a condition
      and thus collide or otherwise produce inconsistent results. You must
      be careful to think about and protect against all the possible ways a
      concurrent system can fail. For example, a task cannot depend on
      another task because task shutdown order is not guaranteed. Here, by
      making tasks depend on non-task objects (which are reference counted
      using CountedPtr) we eliminate the potential race condition.
      -->
      <para>
	La clase <classname>Generator</classname> presenta la clase
	abstracta <classname>Cancelable</classname>, que es parte de
	la biblioteca de ZThread. El propósito
	de <classname>Cancelable</classname> es proporcionar una
	interfaz consistente para cambiar el estado de un objeto via
	cancel() y ver si el objeto ha sido cancelado con la función
	isCanceled(). Aquí utilizamos el enfoque simple de una bandera
	de cancelación booleana similar a quitFlag, vista previamente
	en ResponsiveUI.cpp. Note que en este ejemplo la clase que
	es <classname>Cancelable</classname> no
	es <classname>Runnable</classname>. En su lugar, toda
	tarea <classname>EvenChecker</classname> que dependa de un
	objeto <classname>Cancelable</classname>
	(el <classname>Generator</classname>) lo comprueba para ver
	que ha sido cancelado, como puede ver en run(). De esta
	manera, las tareas que comparten recursos comunes
	(el <classname>Cancelable</classname> <classname>Generator</classname>)
	estén atentos a la señal de ese recurso para terminar. Esto
	elimina la también conocida condición de carrera, donde dos o
	más tareas compiten por responder una condición y, así,
	colisionar o producir resultados inconsistentes. Debe pensar
	sobre esto cuidadosamente y protegerse de todas las formas
	posible de los fallos de un sistema concurrente. Por ejemplo,
	una tarea no puede depender de otra porque el orden de
	finalización de las tareas no está garantizado. En este
	sentido, eliminamos la potencial condición de carrera haciendo
	que las tareas dependan de objetos que no son tareas (que son
	contados referencialmente
	utilizando <classname>CountedPtr</classname>. 
      </para>

      <!--
      In later sections, you?ll see that the ZThread library contains more
      general mechanisms for termination of threads.
      -->
      <para>
	En las secciones posteriores, verá que la librería ZThread
	contiene más mecanismos generales para la terminación de hilos.
      </para>

      <!--
      Since multiple EvenChecker objects may end up sharing a Generator, the
      CountedPtr template is used to reference count the Generator objects.
      -->
      <para>
	Debido a que muchos objetos <classname>EvenChecker</classname>
	podrían terminar compartiendo
	un <classname>Generator</classname>, la
	plantilla <classname>CountedPtr</classname> se usa para contar
	las referencias de los
	objetos <classname>Generator</classname>.
      </para>

      <!--
      The last member function in EvenChecker is a static member template
      that sets up and performs a test of any type of Generator by creating
      one inside a CountedPtr and then starting a number of EvenCheckers
      that use that Generator. If the Generator causes a failure, test( )
      will report it and return; otherwise, you must press Control-C to
      terminate it.
      -->
      <para>
	El último método en <classname>EvenChecker</classname> es un
	miembro estático de la plantilla que configura y realiza una
	comprobación de los tipos de <classname>Generator</classname>
	creando un <classname>CountedPtr</classname> dentro y,
	seguidamente, lanzar un número
	de <classname>EvenChecker</classname>s que usan
	ese <classname>Generator</classname>. Si
	el <classname>Generator</classname> provoca un fallo, test()
	lo reportará y volverá; en otro caso, deberá pulsar Control-C
	para finalizarlo. 
      </para>

      <!--
      EvenChecker tasks constantly read and test the values from their
      associated Generator. Note that if generator->isCanceled( ) is true,
      run( ) returns, which tells the Executor in EvenChecker::test( ) that
      the task is complete. Any EvenChecker task can call cancel( ) on its
      associated Generator, which will cause all other EvenCheckers using
      that Generator to gracefully shut down.
      -->
      <para>
	Las tareas <classname>EvenChecker</classname> leen
	constantemente y comprueban que los valores de
	sus <classname>Generator</classname>s asociados. Vea que si
	generator->isCanceled() es verdadero, run() retorna, con lo
	que se le dice al <classname>Executor</classname> de
	EvenChecker::test() que la tarea se ha
	completado. Cualquier tarea <classname>EvenChecker</classname>
	puede llamar a cancel() sobre
	su <classname>Generator</classname> asociado, lo que causará
	que todos los demás <classname>EvenChecker</classname>s que
	utilicen ese <classname>Generator</classname> finalicen con
	elegancia.     
      </para>

      <!-- The EvenGenerator is simple?nextValue( ) produces the next even value: -->
      <para>
	<classname>EvenGenerator</classname> es simple -
	nextValue() produce el siguiente valor constante:
      </para>


//: V2C11:EvenGenerator.cpp


      <!--
      It?s possible for one thread to call nextValue( ) after the first
      increment of currentEvenValue and before the second (at the place in
      the code commented ?Danger point here!?), which puts the value into an
      ?incorrect? state. To prove that this can happen, EvenChecker::test( )
      creates a group of EvenChecker objects to continually read the output
      of an EvenGenerator and test to see if each one is even. If not, the
      error is reported and the program is shut down.
      -->
      <para>
	Es posible que un hilo llame a nextValue() después de el
	primer incremento de currentEvenValue y antes del segundo (en
	el lugar "Danger point here!" del código comentado), que pone
	el valor en un estado "incorrecto". Para probar que esto puede
	ocurrir, EventChecker::test() crea un grupo de
	objetos <classname>EventChecker</classname> para leer
	continuamente la salida de
	un <classname>EvenGenerator</classname> y ver si cada valor es
	constante. Si no es así, el error se reporta y el programa
	finaliza.
      </para>

      <!--
      This program may not detect the problem until the EvenGenerator has
      completed many cycles, depending on the particulars of your operating
      system and other implementation details. If you want to see it fail
      much faster, try putting a call to yield( ) between the first and
      second increments. In any event, it will eventually fail because the
      EvenChecker threads are able to access the information in
      EvenGenerator while it?s in an ?incorrect? state.
      -->
      <para>
	Este programa podría no detectar el problema hasta
	que <classname>EvenGenerator</classname> ha completado varios
	ciclos, dependiendo de las particuliaridades de su sistema
	operativo y otros detalles de implementación. Si quiere ver
	que falla mucho más rápido, pruebe a poner una llamada a
	yield() entre el primero y segundo incremento. En algún
	evento, fallará puntualmente a causa de que los
	hilos <classname>EvenChecker</classname> pueden acceder a la
	información en <classname>EvenGenerator</classname> mientras
	se encuentra en un estado "incorrecto".
      </para>

    </sect2>
    <sect2>
      <!-- : Controlling access -->
      <title>Control de acceso</title>

      <!--
      The previous example shows a fundamental problem when using threads:
      You never know when a thread might be run. Imagine sitting at a table
      with a fork, about to spear the last piece of food on a platter, and
      as your fork reaches for it, the food suddenly vanishes (because your
      thread was suspended and another diner came in and ate the
      food). That? s the problem you?re dealing with when writing concurrent
      programs.
      -->
      <para>
	En el ejemplo anterior se muestra el problema fundamental a la
	hora de utilizar hilos: nunca sabrá cuándo un hilo puede ser
	ejecutado. Imagínese sentado en la mesa con un tenedor, a
	punto de coger el último pedazo de comida de un plato y tan
	pronto como su tenedor lo alcanza, de repente, la comida se
	desvanece (debido a que su hilo fue suspendido y otro vino y
	se comió la comida). Ese es el problema que estamos tratando a
	la hora de escribir programas concurrentes.
      </para>

      <!--
      Occasionally you don?t care if a resource is being accessed at the
      same time you?re trying to use it. But in most cases you do care, and
      for multithreading to work, you need some way to prevent two threads
      from accessing the same resource, at least during critical periods.
      -->
      <para>
	En ocasiones no le importará si un recurso está siendo
	accedido a la vez que intenta usarlo. Pero en la mayoría de
	los casos sí, y para trabajar con múltiples hilos necesitará
	alguna forma de evitar que dos hilos accedan al mismo recurso,
	al menos durante períodos críticos.
      </para>

      <!--
      Preventing this kind of collision is simply a matter of putting a lock
      on a resource when one thread is using it. The first thread that
      accesses a resource locks it, and then the other threads cannot access
      that resource until it is unlocked, at which time another thread locks
      and uses it, and so on. If the front seat of the car is the limited
      resource, the child who shouts ?Dibs!? acquires the lock.
      -->
      <para>
	Para prevenir este tipo de colisiones existe una manera
	sencilla que consiste en poner un bloqueo sobre un recursos
	cuando un hilo trata de usarlo. El primer hilo que accede al
	recursos lo bloquea y, así, otro hilo no puede acceder al
	recurso hasta que no sea desbloqueado, momento en el que este
	hilo lo vuelve a bloquear y lo vuelve a usar, y así
	sucesivamente.
      </para>

      <!--
      Thus, we need to be able to prevent any other tasks from accessing the
      storage when that storage is not in a proper state. That is, we need
      to have a mechanism that excludes a second task from accessing the
      storage when a first task is already using it. This idea is
      fundamental to all multithreading systems and is called mutual
      exclusion; the mechanism used abbreviates this to mutex. The ZThread
      library contains a mutex mechanism declared in the header Mutex.h.
      -->
      <para>
	De esta forma, tenemos que ser capaces de evitar cualquier
	tarea de acceso a memoria mientras ese almacenamiento no esté
	en un estado adecuado. Esto es, necesitamos tener un mecanismo
	que excluya una segunda tarea sobre el acceso a memoria cuando
	una primera tarea ya está usándola. Esta idea es fundamental
	para todo sistema multihilado y se conoce como exclusión
	mutua; abreviado como mutex. La biblioteca ZThread tiene un
	mecanismo de mutex en el fichero de cabecera Mutex.h.
      </para>

      <!--
      To solve the problem in the above program, we identify the critical
      sections where mutual exclusion must apply; then we acquire the mutex
      before entering the critical section and release it at the end of the
      critical section. Only one thread can acquire the mutex at any time,
      so mutual exclusion is achieved:
      -->
      <para>
	Para solucionar el problema en el programa anterior,
	identificaremos las secciones críticas donde debe aplicarse la
	exclusión mutua; posteriormente, antes de entrar en la sección
	crítica adquiriremos el mutex y lo liberaremos cuando finalice
	la sección crítica. Únicamente un hilo podrá adquirir el mutex
	al mismo tiempo, por lo que se logra exclusión mutua:
      </para>


//: V2C11:MutexEvenGenerator.cpp


      <!--
      MutexEvenGenerator adds a Mutex called lock and uses acquire( ) and
      release( ) to create a critical section within nextValue( ). In
      addition, a call to Thread::yield( ) is inserted between the two
      increments, to raise the likelihood of a context switch while
      currentEvenValue is in an odd state. Because the mutex prevents more
      than one thread at a time in the critical section, this will not
      produce a failure, but calling yield( ) is a helpful way to promote a
      failure if it?s going to happen.
      -->
      <para>
	<classname>MutexEvenGenerator</classname> añade
	un <classname>Mutex</classname> llamado lock y utiliza
	acquire() y release() para crear una sección crítica con
	nextValue(). Además, se ha insertado una llamada a
	Thread::yield() entre los dos incrementos, para aumentar la
	probabilidad de que haya un cambio de contexto mientras
	currentEvenValue se encuentra en un estado extraño. Este hecho
	no producirá un fallo ya que el mutex evita que más de un hilo
	esté en la sección crítica al mismo tiempo, pero llamar a
	yield() es una buena forma de provocar un fallo si este
	ocurriera.
      </para>

      <!--
      Note that nextValue( ) must capture the return value inside the
      critical section because if you return from inside the critical
      section, you won?t release the lock and will thus prevent it from
      being acquired again. (This usually leads to deadlock, which you?ll
      learn about at the end of this chapter.)
      -->
      <para>
	Note que nextValue() debe capturar el valor de retorno dentro
	de la sección crítica porque si lo devolviera dentro de la
	sección critica no liberaría lock y así evitar que fuera
	adquirido. (Normalmente, esto conllevaría un interbloqueo, de
	lo cual aprenderá sobre ello al final de este capítulo.)
      </para>

      <!--
      The first thread that enters nextValue( ) acquires the lock, and any
      further threads that try to acquire the lock are blocked from doing so
      until the first thread releases the lock. At that point, the
      scheduling mechanism selects another thread that is waiting on the
      lock. This way, only one thread at a time can pass through the code
      that is guarded by the mutex.
      -->
      <para>
	El primer hilo que entre en nextValue() adquirirá lock y
	cualquier otro hilo que intente adquirirlo será bloqueado
	hasta que el primer hilo libere lock. En ese momento, el
	mecanismo de planificación selecciona otro hilo que esté
	esperando en lock. De esta manera, solo un hilo puede pasar a
	través del código custodiado por el mutex al mismo tiempo.
      </para>

    </sect2>
    <sect2>
      <!-- : Simplified coding with Guards -->
      <title>Código simplificado mediante guardas</title>

      <!--
      The use of mutexes rapidly becomes complicated when exceptions are
      introduced. To make sure that the mutex is always released, you must
      ensure that each possible exception path includes a call to release(
      ). In addition, any function that has multiple return paths must
      carefully ensure that it calls release( ) at the appropriate points.
	-->
      <para>
	El uso de mutexes se convierte rápidamente complicado cuando
	se introducen excepciones. Para estar seguro de que el mutes
	siempre se libera, debe asegurar que cualquier camino a una
	excepción incluya una llamada a release(). Además, cualquier
	función que tenga múltiples caminos para retornar debe
	asegurar cuidadosamente que se llama a release() en el momento
	adecuado.
      </para>

      <!--
      These problems can be easily solved by using the fact that a
      stack-based (auto) object has a destructor that is always called
      regardless of how you exit from a function scope. In the ZThread
      library, this is implemented as the Guard template. The Guard template
      creates objects that acquire( ) a Lockable object when constructed and
      release( ) that lock when destroyed. Guard objects created on the
      local stack will automatically be destroyed regardless of how the
      function exits and will always unlock the Lockable object. Here?s the
      above example reimplemented using Guards:
      -->
      <para>
	Esos problemas pueden se fácilmente solucionados utilizando el
	hecho de que los objetos de la pila (automáticos) tiene un
	destructor que siempre se llama sea cual sea la forma en que
	salga del ámbito de la función. En la librería ZThread, esto
	se implementa en la plantilla <classname>Guard</classname>. La
	plantilla <classname>Guard</classname> crea objetos que
	adquieren un objeto <classname>Lockable</classname> cuando se
	construyen y lo liberan cuando son destruidos. Los
	objetos <classname>Guard</classname> creados en la pila local
	serán eliminados automáticamente independientemente de la
	forma en el que la función finalice y siempre desbloqueará el
	objeto <classname>Lockable</classname>. A continuación, el
	ejemplo anterior reimplementado para
	utilizar <classname>Guard</classname>s:
      </para>


//: V2C11:GuardedEvenGenerator.cpp {RunByHand}


      <!--
      Note that the temporary return value is no longer necessary in
      nextValue( ). In general, there is less code to write, and the
      opportunity for user error is greatly reduced.
      -->
      <para>
	Note que el valor de retorno temporal ya no es necesario en
	nextValue(). En general, hay menos código que escribir y la
	probabilidad de errores por parte del usuario se reduce en
	gran medida. 
      </para>

      <!--
      An interesting feature of the Guard template is that it can be used to
      manipulate other guards safely. For example, a second Guard can be
      used to temporarily unlock a guard:
      -->
      <para>
	Una característica interesante de la
	plantilla <classname>Guard</classname> es que puede ser usada
	para manipular otros elementos de seguridad. Por ejemplo, un
	segundo <classname>Guard</classname> puede ser utilizado
	temporalmente para desbloquear un elemento de seguridad:
      </para>


//: V2C11:TemporaryUnlocking.cpp


      <!--
      A Guard can also be used to try to acquire a lock for a certain amount
      of time and then give up:
      -->
      <para>
	Un <classname>Guard</classname> también puede utilizarse para
	adquirir un lock durante un determinado tiempo y, después,
	liberarlo: 
      </para>



//: V2C11:TimedLocking.cpp


      <!--
      In this example, a Timeout_Exception will be thrown if the lock cannot
      be acquired within 500 milliseconds.  
      -->
      <para>
	En este ejemplo, se lanzará
	una <classname>Timeout_Exception</classname> si el lock no
	puede ser adquirido en 500 milisegundos. 
      </para>

      <!-- Synchronizing entire classes -->
      <para>Sincronización de clases completas</para>

      <!--
      The ZThread library also provides a GuardedClass template to
      automatically create a synchronized wrapper for an entire class. This
      means that every member function in the class will automatically be
      guarded:
      -->
      <para>
	La librería ZThread también proporciona la
	plantilla <classname>GuardedClass</classname> para crear
	automáticamente un recubrimiento de sincronización para toda
	una clase. Esto quiere decir que cualquier método de una clase
	estará automáticamente protegido:
      </para>


//: V2C11:SynchronizedClass.cpp {-dmc}


      <!--
      Object a is a not synchronized, so func1( ) and func2( ) can be called
      at any time by any number of threads. Object b is protected by the
      GuardedClass wrapper, so each member function is automatically
      synchronized and only one function per object can be called any time.
      -->
      <para>
	El objeto a no está sincronizado, por lo que func1() y func2()
	pueden ser llamadas en cualquier momento por cualquier número
	de hilos. El objeto b está protegido por el
	recubrimiento <classname>GuardedClass</classname>, así que
	cada método se sincroniza automáticamente y solo se puede
	llamar a una función por objeto en cualquier instante. 
      </para>

      <!--
      The wrapper locks at a class level of granularity, which may affect
      performance.[151] If a class contains some unrelated functions, it may
      be better to synchronize those functions internally with two different
      locks. However, if you find yourself doing this, it means that one
      class contains groups of data that may not be strongly
      associated. Consider breaking the class into two classes.
      -->
      <para>
	El recubrimiento bloquea un tipo de nivel de granularidad, que
	podría afectar al rendimiento.[151] Si una clase contiene
	funciones no vinculadas, puede ser mejor sincronizarlas
	internamente con 2 locks diferentes. Sin embargo, si se
	encuentra haciendo esto, significa que la clase contiene
	grupos de datos que puede no estar fuertemente
	asociados. Considere dividir la clase en dos. 
      </para>

      <!--
      Guarding all member functions of a class with a mutex does not
      automatically make that class thread-safe. You must carefully consider
      all threading issues in order to guarantee thread safety.
      -->
      <para>
	Proteger todos los métodos de una clase con un mutex no hace
	que esa clase sea segura automáticamente cuando se utilicen
	hilos. Debe tener cuidado con estas cuestiones para garantizar
	la seguridad cuando se usan hilos.
      </para>

    </sect2>
    <sect2>
      <!-- : Thread local storage -->
      <title>Almacenamiento local al hilo</title>

      <!--
      A second way to eliminate the problem of tasks colliding over shared
      resources is to eliminate the sharing of variables, which can be done
      by creating different storage for the same variable, for each
      different thread that uses an object. Thus, if you have five threads
      using an object with a variable x, thread local storage automatically
      generates five different pieces of storage for x. Fortunately, the
      creation and management of thread local storage is taken care of
      automatically by ZThread?s ThreadLocal template, as seen here:
      -->
      <para>
	Una segunda forma de eliminar el problema de colisión de
	tareas sobre recursos compartidos es la eliminación de las
	variables compartidas, lo cual puede realizarse mediante la
	creación de diferentes almacenamientos para la misma variable,
	uno por cada hilo que use el objeto. De esta forma, si tiene
	cinco hilos que usan un objeto con una variable x, el
	almacenamiento local al hilo genera automáticamente cinco
	porciones de memoria distintas para almacenar
	x. Afortunadamente, la creación y gestión del almacenamiento
	local al hilo la lleva a cabo una plantilla de ZThread
	llamada <classname>ThreadLocal</classname>, tal y como se
	puede ver aquí:
      </para>


//: V2C11:ThreadLocalVariables.cpp {RunByHand}


      <!--
      When you create a ThreadLocal object by instantiating the template,
      you are only able to access the contents of the object using the get(
      ) and set( ) member functions. The get( ) function returns a copy of
      the object that is associated with that thread, and set( ) inserts its
      argument into the object stored for that thread, returning the old
      object that was in storage. You can see this is use in increment( )
      and get( ) in ThreadLocalVariables.
      -->
      <para>
	Cuando crea un objeto <classname>ThreadLocal</classname>
	instanciando la plantilla, únicamente puede acceder al
	contenido del objeto utilizando los métodos set() y get(). El
	método get() devuelve una copia del objeto que está asociado a
	ese hilo, y set() inserta su argumento dentro del objeto
	almacenado para ese hilo, devolviendo el objeto antiguo que se
	encontraba almacenado. Puede comprobar que esto se utiliza en
	increment() y get()
	de <classname>ThreadLocalVariables</classname>.
      </para>

      <!--
      Since tlv is shared by multiple Accessor objects, it is written as
      Cancelable so that the Accessors can be signaled when we want to shut
      the system down.
      -->
      <para>
	Ya que tlv se comparte en múltiples
	objetos <classname>Accessor</classname>, está escrito como
	un <classname>Cancelable</classname>, por lo que
	los <classname>Accessors</classname> puede recibir señales
	cuando queramos parar el sistema.
      </para>

      <!--
      When you run this program, you?ll see evidence that the individual
      threads are each allocated their own storage.
      -->
      <para>
	Cuando ejecute este programa se evidenciará que se reserva
	para cada hilo su propio almacenamiento.
      </para>

    </sect2>
  </sect1>
  <sect1>
    <!-- : Terminating tasks -->
    <title>Finalización de tareas</title>

    <!--
    In previous examples, we have seen the use of a ?quit flag? or the
    Cancelable interface in order to terminate a task. This is a
    reasonable approach to the problem. However, in some situations the
    task must be terminated more abruptly. In this section, you?ll learn
    about the issues and problems of such termination.
    -->
    <para>
      En los ejemplos anteriores, hemos visto el uso de una "bandera
      de terminación" o de la
      interfaz <classname>Cancelable</classname> para finalizar una
      tarea. Este es un enfoque razonable para el problema. Sin
      embargo, en algunas ocasiones la tarea tiene que ser finalizada
      más abruptamente. En esta sección, aprenderá sobre las
      cuestiones y problemas de este tipo de finalización.
    </para>

    <!--
    First, let?s look at an example that not only demonstrates the
    termination problem but is also an additional example of resource
    sharing. To present this example, we?ll first need to solve the
    problem of iostream collision
    -->
    <para>
      Primeramente, veamos en un ejemplo que no sólo demuestra el
      problema de la finalización sino que, además, es un ejemplo
      adicional de comparición de recursos. Para mostrar el ejemplo,
      primero necesitaremos resolver el problema de la colisión de
      iostream.
    </para>

    <sect2>
      <!-- : Preventing iostream collision -->
      <title>Prevención de coliciones en iostream</title>

      <!--
      You may have noticed in previous examples that the output is sometimes
      garbled. C++ iostreams were not created with threading in mind, so
      there?s nothing to keep one thread?s output from interfering with
      another thread?s output. Thus, you must write your applications so
      that they synchronize the use of iostreams.
      -->
      <para>

      </para>

      <!--
      To solve the problem, we need to create the entire output packet first
      and then explicitly decide when to try to send it to the console. One
      simple solution is to write the information to an ostringstream and
      then use a single object with a mutex as the point of output among all
      threads, to prevent more than one thread from writing at the same
      time:
      -->
      <para>

      </para>


//: V2C11:Display.h


      <!--
      This way, the standard operator<<( ) functions are predefined for us
      and the object can be built in memory using familiar ostream
      operators. When a task wants to display output, it creates a temporary
      ostringstream object that it uses to build up the desired output
      message. When it calls output( ), the mutex prevents multiple threads
      from writing to this Display object. (You must use only one Display
      object in your program, as you?ll see in the following examples.)
      -->
      <para>

      </para>

      <!--
      This just shows the basic idea, but if necessary, you can build a more
      elaborate framework. For example, you could enforce the requirement
      that there be only one Display object in a program by making it a
      Singleton. (The ZThread library has a Singleton template to support
      Singletons.)
      -->
      <para>

      </para>

    </sect2>
    <sect2>
      <!-- : The ornamental garden -->
      <title>El jardín ornamental</title>

      <!--
      In this simulation, the garden committee would like to know how many
      people enter the garden each day through its multiple gates. Each gate
      has a turnstile or some other kind of counter, and after the turnstile
      count is incremented, a shared count is incremented that represents
      the total number of people in the garden.
      -->
      <para>

      </para>


//: V2C11:OrnamentalGarden.cpp {RunByHand}


      <!--
      Count is the class that keeps the master count of garden visitors. The
      single Count object defined in main( ) as count is held as a
      CountedPtr in Entrance and thus is shared by all Entrance objects. A
      FastMutex called lock is used in this example instead of an ordinary
      Mutex because a FastMutex uses the native operating system mutex and
      will thus yield more interesting results.
      -->
      <para>

      </para>

      <!--
      A Guard is used with lock in increment( ) to synchronize access to
      count. This function uses rand( ) to cause a yield( ) roughly half the
      time, in between fetching count into temp and incrementing and storing
      temp back into count. Because of this, if you comment out the Guard
      object definition, you will rapidly see the program break because
      multiple threads will be accessing and modifying count simultaneously.
      -->
      <para>

      </para>

      <!--
      The Entrance class also keeps a local number with the number of
      visitors that have passed through this particular entrance. This
      provides a double-check against the count object to make sure that the
      proper number of visitors is being recorded. Entrance::run( ) simply
      increments number and the count object and sleeps for 100
      milliseconds.
      -->
      <para>

      </para>

      <!--
      In main, a vector<Entrance*> is loaded with each Entrance that is
      created. After the user presses <Enter>, this vector is used to
      iterate over all the individual Entrance values and total them.
      -->
      <para>

      </para>

      <!--
      This program goes to quite a bit of extra trouble to shut everything
      down in a stable fashion. Part of the reason for this is to show just
      how careful you must be when terminating a multithreaded program, and
      part of the reason is to demonstrate the value of interrupt( ), which
      you will learn about shortly.
      -->
      <para>

      </para>

      <!--
      All the communication between the Entrance objects takes place through
      the single Count object. When the user presses <Enter>, main( ) sends
      the pause( ) message to count. Since each Entrance::run( ) is watching
      the count object to see whether it is paused, this causes each
      Entrance to move into the waitingForCancel state, where it is no
      longer counting, but it is still alive. This is essential because
      main( ) must still be able to safely iterate over the objects in the
      vector<Entrance*>. Note that because there is a slight possibility
      that the iteration might occur before an Entrance has finished
      counting and moved into the waitingForCancel state, the getValue( )
      function cycles through calls to sleep( ) until the object moves into
      waitingForCancel. (This is one form of what is called a busy wait,
      which is undesirable. You?ll see the preferred approach of using wait(
      ) later in the chapter.) Once main( ) completes its iteration through
      the vector<Entrance*>, the cancel( ) message is sent to the count
      object, and once again all the Entrance objects are watching for this
      state change. At this point, they print a termination message and exit
      from run( ), which causes each task to be destroyed by the threading
      mechanism.
      -->
      <para>

      </para>

      <!--
      As this program runs, you will see the total count and the count at
      each entrance displayed as people walk through a turnstile. If you
      comment out the Guard object in Count::increment( ), you?ll notice
      that the total number of people is not what you expect it to be. The
      number of people counted by each turnstile will be different from the
      value in count. As long as the Mutex is there to synchronize access to
      the Counter, things work correctly. Keep in mind that
      Count::increment( ) exaggerates the potential for failure by using
      temp and yield( ). In real threading problems, the possibility for
      failure may be statistically small, so you can easily fall into the
      trap of believing that things are working correctly. Just as in the
      example above, there are likely to be hidden problems that haven?t
      occurred to you, so be exceptionally diligent when reviewing
      concurrent code.  Atomic operations
      -->
      <para>

      </para>

      <!--
      Note that Count::value( ) returns the value of count using a Guard
      object for synchronization. This brings up an interesting point
      because this code will probably work fine with most compilers and
      systems without synchronization. The reason is that, in general, a
      simple operation such as returning an int will be an atomic operation,
      which means that it will probably happen in a single microprocessor
      instruction that will not get interrupted. (The multithreading
      mechanism is unable to stop a thread in the middle of a microprocessor
      instruction.) That is, atomic operations are not interruptible by the
      threading mechanism and thus do not need to be guarded.[152] In fact,
      if we removed the fetch of count into temp and removed the yield( ),
      and instead simply incremented count directly, we probably wouldn?t
      need a lock because the increment operation is usually atomic, as
      well.[153]
      -->
      <para>

      </para>

      <!--
      The problem is that the C++ Standard doesn?t guarantee atomicity for
      any of these operations. Although operations such as returning an int
      and incrementing an int are almost certainly atomic on most machines,
      there?s no guarantee. And because there?s no guarantee, you have to
      assume the worst. Sometimes you might investigate the atomicity
      behavior on a particular machine (usually by looking at assembly
      language) and write code based on those assumptions. That?s always
      dangerous and ill-advised. It?s too easy for that information to be
      lost or hidden, and the next person that comes along may assume that
      this code can be ported to another machine and then go mad tracking
      down the occasional glitch caused by thread collisions.
      -->
      <para>

      </para>

      <!--
      So, while removing the guard on Count::value( ) seems to work, it?s
      not airtight, and thus on some machines you may see aberrant behavior.
      -->
      <para>

      </para>

    </sect2>
    <sect2>
      <!-- : Terminating when blocked -->
      <title>FIXME:Teminación en el bloqueo</title>

      <!--
      Entrance::run( ) in the previous example includes a call to sleep( )
      in the main loop. We know that sleep( ) will eventually wake up and
      the task will reach the top of the loop where it has an opportunity to
      break out of that loop by checking the isPaused( ) status. However,
      sleep( ) is just one situation where a thread is blocked from
      executing, and sometimes you must terminate a task that?s blocked.
      Thread states
      -->
      <para>

      </para>

      <!-- A thread can be in any one of four states: -->
      <para>

      </para>

      <!--
      1.  New: A thread remains in this state only momentarily, as it is
      being created. It allocates any necessary system resources and
      performs initialization. At this point it becomes eligible to receive
      CPU time. The scheduler will then transition this thread to the
      runnable or blocked state.
      -->
      <para>

      </para>

      <!--
      2.  Runnable: This means that a thread can be run when the
      time-slicing mechanism has CPU cycles available for the thread. Thus,
      the thread might or might not be running at any moment, but there?s
      nothing to prevent it from being run if the scheduler can arrange it;
      it?s not dead or blocked.
      -->
      <para>

      </para>

      <!--
      3.  Blocked: The thread could be run, but something prevents it. (It
      might be waiting for I/O to complete, for example.) While a thread is
      in the blocked state, the scheduler will simply skip it and not give
      it any CPU time. Until a thread reenters the runnable state, it won?t
      perform any operations.
      -->
      <para>

      </para>

      <!--
      4.  Dead: A thread in the dead state is no longer schedulable and will
      not receive any CPU time. Its task is completed, and it is no longer
      runnable. The normal way for a thread to die is by returning from its
      run( ) function.  Becoming blocked
      -->
      <para>

      </para>

      <!--
      A thread is blocked when it cannot continue running. A thread can
      become blocked for the following reasons:
      -->
      <para>

      </para>

      <!--
      · You?ve put the thread to sleep by calling sleep(milliseconds), in
      which case it will not be run for the specified time.
      -->
      <para>

      </para>

      <!--
      · You?ve suspended the execution of the thread with wait( ). It will
      not become runnable again until the thread gets the signal( )
      or broadcast( ) message. We?ll examine these in a later
      section.
      -->
      <para>

      </para>

      <!-- · The thread is waiting for some I/O to complete. -->
      <para>

      </para>

      <!--
      · The thread is trying to enter a block of code that is guarded by a
      mutex, and that mutex has already been acquired by another
      thread.
      -->
      <para>

      </para>

      <!--
      The problem we need to look at now is this: sometimes you want to
      terminate a thread that is in a blocked state. If you can?t wait for
      it to get to a point in the code where it can check a state value and
      decide to terminate on its own, you have to force the thread out of
      its blocked state.
      -->
      <para>

      </para>

    </sect2>
    <sect2>
      <!-- : Interruption -->
      <title>Interrupción</title>

      <!--
      As you might imagine, it?s much messier to break out of the middle of
      a Runnable::run( ) function than it is to wait for that function to
      get to a test of isCanceled( ) (or some other place where the
      programmer is ready to leave the function). When you break out of a
      blocked task, you might need to destroy objects and clean up
      resources. Because of this, breaking out of the middle of a task?s
      run( ) is more like throwing an exception than anything else, so in
      ZThreads, exceptions are used for this kind of abort. (This walks the
      fine edge of being an inappropriate use of exceptions, because it
      means you are often using them for control flow.)[154] To return to a
      known good state when terminating a task this way, carefully consider
      the execution paths of your code and properly clean up everything
      inside the catch clause. We?ll look at these issues in this section.
      -->
      <para>

      </para>

      <!--
      To terminate a blocked thread, the ZThread library provides the
      Thread::interrupt( ) function. This sets the interrupted status for
      that thread. A thread with its interrupted status set will throw an
      Interrupted_Exception if it is already blocked or it attempts a
      blocking operation. The interrupted status will be reset when the
      exception is thrown or if the task calls Thread::interrupted( ). As
      you?ll see, Thread::interrupted( ) provides a second way to leave your
      run( ) loop, without throwing an exception.
      -->
      <para>

      </para>

      <!-- Here?s an example that shows the basics of interrupt( ): -->
      <para>

      </para>


//: V2C11:Interrupting.cpp


      <!--
      You can see that, in addition to the insertion into cout, run( )
      contains two other points where blocking can occur: the call to
      Thread::sleep(1000) and the call to cin.get( ). By giving the program
      any command-line argument, you tell main( ) to sleep long enough that
      the task will finish its sleep( ) and call cin.get( ).[155] If you
      don? t give the program an argument, the sleep( ) in main( ) is
      skipped. Here, the call to interrupt( ) will occur while the task is
      sleeping, and you?ll see that this will cause Interrupted_Exception to
      be thrown. If you give the program a command-line argument, you?ll
      discover that a task cannot be interrupted if it is blocked on
      IO. That is, you can interrupt out of any blocking operation except
      IO.[156]
      -->
      <para>

      </para>

      <!--
      This is a little disconcerting if you?re creating a thread that
      performs IO because it means that I/O has the potential of locking
      your multithreaded program. The problem is that, again, C++ was not
      designed with threading in mind; quite the opposite, it effectively
      pretends that threading doesn?t exist. Thus, the iostream library is
      not thread-friendly. If the new C++ Standard decides to add thread
      support, the iostream library may need to be reconsidered in the
      process.  Blocked by a mutex
      -->
      <para>

      </para>

      <!--
      If you try to call a function whose mutex has already been acquired,
      the calling task will be suspended until the mutex becomes
      available. The following example tests whether this kind of blocking
      is interruptible:
      -->
      <para>

      </para>


//: V2C11:Interrupting2.cpp


      <!--
      The class BlockedMutex has a constructor that acquires the object?s
      own Mutex and never releases it. For that reason, if you try to call
      f( ), you will always be blocked because the Mutex cannot be
      acquired. In Blocked2, the run( ) function will be stopped at the call
      to blocked.f( ). When you run the program you?ll see that, unlike the
      iostream call, interrupt( ) can break out of a call that?s blocked by
      a mutex.[157] Checking for an interrupt
      -->
      <para>

      </para>

      <!--
      Note that when you call interrupt( ) on a thread, the only time that
      the interrupt occurs is when the task enters, or is already inside, a
      blocking operation (except, as you?ve seen, in the case of IO, where
      you?re just stuck). But what if you?ve written code that may or may
      not make such a blocking call, depending on the conditions in which it
      is run? If you can only exit by throwing an exception on a blocking
      call, you won?t always be able to leave the run( ) loop. Thus, if you
      call interrupt( ) to stop a task, your task needs a second opportunity
      to exit in the event that your run( ) loop doesn?t happen to be making
      any blocking calls.
      -->
      <para>

      </para>

      <!--
      This opportunity is presented by the interrupted status, which is set
      by the call to interrupt( ). You check for the interrupted status by
      calling interrupted( ). This not only tells you whether interrupt( )
      has been called, it also clears the interrupted status. Clearing the
      interrupted status ensures that the framework will not notify you
      twice about a task being interrupted. You will be notified via either
      a single Interrupted_Exception, or a single successful
      Thread::interrupted( ) test. If you want to check again to see whether
      you were interrupted, you can store the result when you call
      Thread::interrupted( ).
      -->
      <para>

      </para>

      <!--
      The following example shows the typical idiom that you should use in
      your run( ) function to handle both blocked and non-blocked
      possibilities when the interrupted status is set:
      -->
      <para>

      </para>


//: V2C11:Interrupting3.cpp {RunByHand}


      <!--
      The NeedsCleanup class emphasizes the necessity of proper resource
      cleanup if you leave the loop via an exception. Note that no pointers
      are defined in Blocked3::run( ) because, for exception safety, all
      resources must be enclosed in stack-based objects so that the
      exception handler can automatically clean them up by calling the
      destructor.
      -->
      <para>

      </para>

      <!--
      You must give the program a command-line argument which is the delay
      time in milliseconds before it calls interrupt( ). By using different
      delays, you can exit Blocked3::run( ) at different points in the loop:
      in the blocking sleep( ) call, and in the non-blocking mathematical
      calculation. You?ll see that if interrupt( ) is called after the label
      point2 (during the non-blocking operation), first the loop is
      completed, then all the local objects are destructed, and finally the
      loop is exited at the top via the while statement. However, if
      interrupt( ) is called between point1 and point2 (after the while
      statement but before or during the blocking operation sleep( )), the
      task exits via the Interrupted_Exception. In that case, only the stack
      objects that have been created up to the point where the exception is
      thrown are cleaned up, and you have the opportunity to perform any
      other cleanup in the catch clause.
      -->
      <para>

      </para>

      <!--
      A class designed to respond to an interrupt( ) must establish a policy
      that ensures it will remain in a consistent state. This generally
      means that all resource acquisition should be wrapped inside
      stack-based objects so that the destructors will be called regardless
      of how the run( ) loop exits. Correctly done, code like this can be
      elegant. Components can be created that completely encapsulate their
      synchronization mechanisms but are still responsive to an external
      stimulus (via interrupt( )) without adding any special functions to an
      object?s interface.
      -->
      <para>

      </para>

    </sect2>
  </sect1>
  <sect1>
    <!-- : Cooperation between threads -->
    <title>Cooperación entre hilos</title>

    <!--
    As you?ve seen, when you use threads to run more than one task at a
    time, you can keep one task from interfering with another task?s
    resources by using a mutex to synchronize the behavior of the two
    tasks. That is, if two tasks are stepping on each other over a shared
    resource (usually memory), you use a mutex to allow only one task at a
    time to access that resource.
    -->
    <para>

    </para>

    <!--
    With that problem solved, you can move on to the issue of getting
    threads to cooperate, so that multiple threads can work together to
    solve a problem. Now the issue is not about interfering with one
    another, but rather about working in unison, since portions of such
    problems must be solved before other portions can be solved. It?s much
    like project planning: the footings for the house must be dug first,
    but the steel can be laid and the concrete forms can be built in
    parallel, and both of those tasks must be finished before the concrete
    foundation can be poured. The plumbing must be in place before the
    concrete slab can be poured, the concrete slab must be in place before
    you start framing, and so on. Some of these tasks can be done in
    parallel, but certain steps require all tasks to be completed before
    you can move ahead.
    -->
    <para>

    </para>

    <!--
    The key issue when tasks are cooperating is handshaking between those
    tasks. To accomplish this handshaking, we use the same foundation: the
    mutex, which in this case guarantees that only one task can respond to
    a signal. This eliminates any possible race conditions. On top of the
    mutex, we add a way for a task to suspend itself until some external
    state changes (?the plumbing is now in place?), indicating that it? s
    time for that task to move forward. In this section, we?ll look at the
    issues of handshaking between tasks, the problems that can arise, and
    their solutions.
    -->
    <para>

    </para>

    <sect2>
      <!-- : Wait and signal -->
      <title>Wait y signal</title>

      <!--
      In ZThreads, the basic class that uses a mutex and allows task
      suspension is the Condition, and you can suspend a task by calling
      wait( ) on a Condition. When external state changes take place that
      might mean that a task should continue processing, you notify the task
      by calling signal( ), to wake up one task, or broadcast( ), to wake up
      all tasks that have suspended themselves on that Condition object.
      -->
      <para>

      </para>

      <!--
      There are two forms of wait( ). The first form takes an argument in
      milliseconds that has the same meaning as in sleep( ): ?pause for this
      period of time.? The second form takes no arguments; this version is
      more commonly used. Both forms of wait( ) release the Mutex that is
      controlled by the Condition object and suspends the thread until that
      Condition object receives a signal( ) or broadcast( ). The first form
      may also terminate if it times out before a signal( ) or broadcast( )
      is received.
      -->
      <para>

      </para>

      <!--
      Because wait( ) releases the Mutex, it means that the Mutex can be
      acquired by another thread. Thus, when you call wait( ) you?re saying
      ?I?ve done all I can right now so I?m going to wait right here, but I
      want to allow other synchronized operations to take place if they
      can.?
      -->
      <para>

      </para>

      <!--
      Typically, you use wait( ) when you?re waiting for some condition to
      change that is under the control of forces outside the current
      function. (Often, this condition will be changed by another thread.)
      You don?t want to idly loop while testing the condition inside your
      thread; this is called a ?busy wait,? and it?s usually a bad use of
      CPU cycles. Thus, wait( ) suspends the thread while waiting for the
      world to change, and only when a signal( ) or broadcast( ) occurs
      (suggesting that something of interest may have happened), does the
      thread wake up and check for changes. So wait( ) provides a way to
      synchronize activities between threads.
      -->
      <para>

      </para>

      <!--
      Let?s look at a simple example. WaxOMatic.cpp has two processes: one
      to apply wax to a Car and one to polish it. The polishing process
      cannot do its job until the application process is finished, and the
      application process must wait until the polishing process is finished
      before it can put on another coat of wax. Both WaxOn and WaxOff use
      the Car object, which contains a Condition that it uses to suspend a
      thread inside waitForWaxing( ) or waitForBuffing( ):
      -->
      <para>

      </para>


//: V2C11:WaxOMatic.cpp {RunByHand}


      <!--
      In Car?s constructor, a single Mutex is wrapped in a Condition object
      so that it can be used to manage inter-task communication. However,
      the Condition object contains no information about the state of your
      process, so you need to manage additional information to indicate
      process state. Here, Car has a single bool waxOn, which indicates the
      state of the waxing-polishing process.
      -->
      <para>

      </para>

      <!--
      In waitForWaxing( ), the waxOn flag is checked, and if it is false,
      the calling thread is suspended by calling wait( ) on the Condition
      object. It?s important that this occur inside a guarded clause, where
      the thread has acquired the lock (here, by creating a Guard
      object). When you call wait( ), the thread is suspended and the lock
      is released. It is essential that the lock be released because, to
      safely change the state of the object (for example, to change waxOn to
      true, which must happen if the suspended thread is to ever continue),
      that lock must be available to be acquired by some other task. In this
      example, when another thread calls waxed( ) to tell it that it?s time
      to do something, the mutex must be acquired in order to change waxOn
      to true. Afterward, waxed( ) sends a signal( ) to the Condition
      object, which wakes up the thread suspended in the call to wait(
      ). Although signal( ) may be called inside a guarded clause?as it is
      here?you are not required to do this.[158]
      -->
      <para>

      </para>

      <!--
      In order for a thread to wake up from a wait( ), it must first
      reacquire the mutex that it released when it entered the wait( ). The
      thread will not wake up until that mutex becomes available.
      -->
      <para>

      </para>

      <!--
      The call to wait( ) is placed inside a while loop that checks the
      condition of interest. This is important for two reasons:[159]
      -->
      <para>

      </para>

      <!--
      · It is possible that when the thread gets a signal( ), some other
      condition has changed that is not associated with the reason
      that we called wait( ) here. If that is the case, this thread
      should be suspended again until its condition of interest
      changes.
      -->
      <para>

      </para>

      <!--
      · By the time this thread awakens from its wait( ), it?s possible that
      some other task has changed things such that this thread is
      unable or uninterested in performing its operation at this
      time. Again, it should be re-suspended by calling wait( )
      again.
      -->
      <para>

      </para>

      <!--
      Because these two reasons are always present when you are calling
      wait( ), always write your call to wait( ) inside a while loop that
      tests for your condition(s) of interest.
      -->
      <para>

      </para>

      <!--
      WaxOn::run( ) represents the first step in the process of waxing the
      car, so it performs its operation (a call to sleep( ) to simulate the
      time necessary for waxing). It then tells the car that waxing is
      complete, and calls waitForBuffing( ), which suspends this thread with
      a wait( ) until the WaxOff process calls buffed( ) for the car,
      changing the state and calling notify( ). WaxOff::run( ), on the other
      hand, immediately moves into waitForWaxing( ) and is thus suspended
      until the wax has been applied by WaxOn and waxed( ) is called. When
      you run this program, you can watch this two-step process repeat
      itself as control is handed back and forth between the two
      threads. When you press the <Enter> key, interrupt( ) halts both
      threads?when you call interrupt( ) for an Executor, it calls
      interrupt( ) for all the threads it is controlling.
      -->
      <para>

      </para>

    </sect2>
    <sect2>
      <!-- : Producer?consumer relationships -->
      <title>Relación de productor/consumidor</title>

      <!--
      A common situation in threading problems is the producer-consumer
      relationship, where one task is creating objects and other tasks are
      consuming them. In such a situation, make sure that (among other
      things) the consuming tasks do not accidentally skip any of the
      produced objects.
      -->
      <para>

      </para>

      <!--
      To show this problem, consider a machine that has three tasks: one to
      make toast, one to butter the toast, and one to put jam on the
      buttered toast.
      -->
      <para>

      </para>


//: V2C11:ToastOMatic.cpp {RunByHand}


      <!--
      The classes are defined in the reverse order that they operate to
      simplify forward-referencing issues.
      -->
      <para>

      </para>

      <!--
      Jammer and Butterer both contain a Mutex, a Condition, and some kind
      of internal state information that changes to indicate that the
      process should suspend or resume. (Toaster doesn?t need these since it
      is the producer and doesn?t have to wait on anything.) The two run( )
      functions perform an operation, set a state flag, and then call wait(
      ) to suspend the task. The moreToastReady( ) and
      moreButteredToastReady( ) functions change their respective state
      flags to indicate that something has changed and the process should
      consider resuming and then call signal( ) to wake up the thread.
      -->
      <para>

      </para>

      <!--
      The difference between this example and the previous one is that, at
      least conceptually, something is being produced here: toast. The rate
      of toast production is randomized a bit, to add some uncertainty. And
      you?ll see that when you run the program, things aren?t going right
      because many pieces of toast appear to be getting dropped on the
      floor?not buttered, not jammed.
      -->
      <para>

      </para>

    </sect2>
    <sect2>
      <!-- : Solving threading problems with queues -->
      <title>Resolución de problemas de hilos mediante colas</title>

      <!--
      Often, threading problems are based on the need for tasks to be
      serialized?that is, to take care of things in order. ToastOMatic.cpp
      must not only take care of things in order, it must be able to work on
      one piece of toast without worrying that toast is falling on the floor
      in the meantime. You can solve many threading problems by using a
      queue that synchronizes access to the elements within:
      -->
      <para>

      </para>


//: V2C11:TQueue.h 


      <!-- This builds on the Standard C++ Library deque by adding: -->
      <para>

      </para>

      <!--
      1.  Synchronization to ensure that no two threads add objects at the
      same time.
      -->
      <para>

      </para>

      <!--
      2.  wait( ) and signal( ) so that a consumer thread will automatically
      suspend if the queue is empty, and resume when more elements become
      available.
      -->
      <para>

      </para>

      <!--
      This relatively small amount of code can solve a remarkable number of
      problems.[160]
      -->
      <para>

      </para>

      <!--
      Here?s a simple test that serializes the execution of LiftOff
      objects. The consumer is LiftOffRunner, which pulls each LiftOff
      object off the TQueue and runs it directly. (That is, it uses its own
      thread by calling run( ) explicitly rather than starting up a new
      thread for each task.)
      -->
      <para>

      </para>


//: V2C11:TestTQueue.cpp {RunByHand}


      <!--
      The tasks are placed on the TQueue by main( ) and are taken off the
      TQueue by the LiftOffRunner. Notice that LiftOffRunner can ignore the
      synchronization issues because they are solved by the TQueue.  Proper
      toasting
      -->
      <para>

      </para>

      <!--
      To solve the ToastOMatic.cpp problem, we can run the toast through
      TQueues between processes. And to do this, we will need actual toast
      objects, which maintain and display their state:
      -->
      <para>

      </para>


//: V2C11:ToastOMaticMarkII.cpp {RunByHand}


      <!--
      Two things are immediately apparent in this solution: first, the
      amount and complexity of code within each Runnable class is
      dramatically reduced by the use of the TQueue because the guarding,
      communication, and wait( )/signal( ) operations are now taken care of
      by the TQueue. The Runnable classes don?t have Mutexes or Condition
      objects anymore. Second, the coupling between the classes is
      eliminated because each class communicates only with its
      TQueues. Notice that the definition order of the classes is now
      independent. Less code and less coupling are always good things, which
      suggests that the use of the TQueue has a positive effect here, as it
      does on most problems.
      -->
      <para>

      </para>

    </sect2>
    <sect2>
      <!-- : Broadcast -->
      <title>Broadcast </title>

      <!--
      The signal( ) function wakes up one thread that is waiting on a
      Condition object. However, multiple threads may be waiting on the same
      condition object, and in that case you might want to wake them all up
      using broadcast( ) instead of signal( ).
      -->
      <para>

      </para>

      <!--
      As an example that brings together many of the concepts in this
      chapter, consider a hypothetical robotic assembly line for
      automobiles. Each Car will be built in several stages, and in this
      example we?ll look at a single stage: after the chassis has been
      created, at the time when the engine, drive train, and wheels are
      attached. The Cars are transported from one place to another via a
      CarQueue, which is a type of TQueue. A Director takes each Car (as a
      raw chassis) from the incoming CarQueue and places it in a Cradle,
      which is where all the work is done. At this point, the Director tells
      all the waiting robots (using broadcast( )) that the Car is in the
      Cradle ready for the robots to work on it. The three types of robots
      go to work, sending a message to the Cradle when they finish their
      tasks. The Director waits until all the tasks are complete and then
      puts the Car onto the outgoing CarQueue to be transported to the next
      operation. Here, the consumer of the outgoing CarQueue is a Reporter
      object, which just prints the Car to show that the tasks have been
      properly completed.
      -->
      <para>

      </para>


//: V2C11:CarBuilder.cpp {RunByHand}


      <!--
      You?ll notice that Car takes a shortcut: it assumes that bool
      operations are atomic, which, as previously discussed, is sometimes a
      safe assumption but requires careful thought.[161] Each Car begins as
      an unadorned chassis, and different robots will attach different parts
      to it, calling the appropriate ?add? function when they do.
      -->
      <para>

      </para>

      <!--
      A ChassisBuilder simply creates a new Car every second and places it
      into the chassisQueue. A Director manages the build process by taking
      the next Car off the chassisQueue, putting it into the Cradle, telling
      all the robots to startWork( ), and suspending itself by calling
      waitUntilWorkFinished( ). When the work is done, the Director takes
      the Car out of the Cradle and puts in into the finishingQueue.
      -->
      <para>

      </para>

      <!--
      The Cradle is the crux of the signaling operations. A Mutex and a
      Condition object control both the working of the robots and indicate
      whether all the operations are finished. A particular type of robot
      can offer its services to the Cradle by calling the ?offer? function
      appropriate to its type. At this point, that robot thread is suspended
      until the Director calls startWork( ), which changes the hiring flags
      and calls broadcast( ) to tell all the robots to show up for
      work. Although this system allows any number of robots to offer their
      services, each one of those robots has its thread suspended by doing
      so. You could imagine a more sophisticated system where the robots
      register themselves with many different Cradles without being
      suspended by that registration process and then reside in a pool
      waiting for the first Cradle that needs a task completed.
      -->
      <para>

      </para>

      <!--
      After each robot finishes its task (changing the state of the Car in
      the process), it calls taskFinished( ), which sends a signal( ) to the
      readyCondition, which is what the Director is waiting on in
      waitUntilWorkFinished( ). Each time the director thread awakens, the
      state of the Car is checked, and if it still isn?t finished, that
      thread is suspended again.
      -->
      <para>

      </para>

      <!--
      When the Director inserts a Car into the Cradle, you can perform
      operations on that Car via the operator->( ). To prevent multiple
      extractions of the same car, a flag causes an error report to be
      generated. (Exceptions don?t propagate across threads in the ZThread
      library.)
      -->
      <para>

      </para>

      <!--
      In main( ), all the necessary objects are created and the tasks are
      initialized, with the ChassisBuilder begun last to start the
      process. (However, because of the behavior of the TQueue, it wouldn?t
      matter if it were started first.) Note that this program follows all
      the guidelines regarding object and task lifetime presented in this
      chapter, and so the shutdown process is safe.
      -->
      <para>

      </para>

    </sect2>
  </sect1>
  <sect1>
    <!-- : Deadlock -->
    <title>Bloqueo letal</title>

    <!--
    Because threads can become blocked and because objects can have
    mutexes that prevent threads from accessing that object until the
    mutex is released, it?s possible for one thread to get stuck waiting
    for another thread, which in turn waits for another thread, and so on,
    until the chain leads back to a thread waiting on the first one. You
    get a continuous loop of threads waiting on each other, and no one can
    move. This is called deadlock.
    -->
    <para>

    </para>

    <!--
    If you try running a program and it deadlocks right away, you
    immediately know you have a problem, and you can track it down. The
    real problem is when your program seems to be working fine but has the
    hidden potential to deadlock. In this case, you may get no indication
    that deadlocking is a possibility, so it will be latent in your
    program until it unexpectedly happens to a customer. (And you probably
    won?t be able to easily reproduce it.) Thus, preventing deadlock
    through careful program design is a critical part of developing
    concurrent programs.
    -->
    <para>

    </para>

    <!--
    Let?s look at the classic demonstration of deadlock, invented by
    Edsger Dijkstra: the dining philosophers problem. The basic
    description specifies five philosophers (but the example shown here
    will allow any number). These philosophers spend part of their time
    thinking and part of their time eating. While they are thinking, they
    don?t need any shared resources, but they eat using a limited number
    of utensils. In the original problem description, the utensils are
    forks, and two forks are required to get spaghetti from a bowl in the
    middle of the table, but it seems to make more sense to say that the
    utensils are chopsticks. Clearly, each philosopher will require two
    chopsticks in order to eat.
    -->
    <para>

    </para>

    <!--
    A difficulty is introduced into the problem: as philosophers, they
    have very little money, so they can only afford five chopsticks. These
    are spaced around the table between them. When a philosopher wants to
    eat, they must pick up the chopstick to the left and the one to the
    right. If the philosopher on either side is using a desired chopstick,
    our philosopher must wait until the necessary chopsticks become
    available.
    -->
    <para>

    </para>


//: V2C11:DiningPhilosophers.h


    <!--
    No two Philosophers can take( ) a Chopstick at the same time, since
    take( ) is synchronized with a Mutex. In addition, if the chopstick
    has already been taken by one Philosopher, another can wait( ) on the
    available Condition until the Chopstick becomes available when the
    current holder calls drop( ) (which must also be synchronized to
    prevent race conditions and ensure memory visibility in multiprocessor
    systems).
    -->
    <para>

    </para>

    <!--
    Each Philosopher holds references to their left and right Chopstick so
    they can attempt to pick those up. The goal of the Philosopher is to
    think part of the time and eat part of the time, and this is expressed
    in main( ). However, you will observe that if the Philosophers spend
    very little time thinking, they will all be competing for the
    Chopsticks while they try to eat, and deadlock will happen much more
    quickly. So you can experiment with this, the ponderFactor weights the
    length of time that a Philosopher tends to spend thinking and
    eating. A smaller ponderFactor will increase the probability of
    deadlock.
    -->
    <para>

    </para>

    <!--
    In Philosopher::run( ), each Philosopher just thinks and eats
    continuously. You see the Philosopher thinking for a randomized amount
    of time, then trying to take( ) the right and then the left Chopstick,
    eating for a randomized amount of time, and then doing it
    again. Output to the console is synchronized as seen earlier in this
    chapter.
    -->
    <para>

    </para>

    <!--
    This problem is interesting because it demonstrates that a program can
    appear to run correctly but actually be deadlock prone. To show this,
    the command-line argument adjusts a factor to affect the amount of
    time each philosopher spends thinking. If you have lots of
    philosophers or they spend a lot of time thinking, you may never see
    the deadlock even though it remains a possibility. A command-line
    argument of zero tends to make it deadlock fairly quickly:[162]
    -->
    <para>

    </para>


//: V2C11:DeadlockingDiningPhilosophers.cpp {RunByHand}


    <!--
    Note that the Chopstick objects do not need internal identifiers; they
    are identified by their position in the array c. Each Philosopher is
    given a reference to a left and right Chopstick object when
    constructed; these are the utensils that must be picked up before that
    Philosopher can eat. Every Philosopher except the last one is
    initialized by situating that Philosopher between the next pair of
    Chopstick objects. The last Philosopher is given the zeroth Chopstick
    for its right Chopstick, so the round table is completed. That?s
    because the last Philosopher is sitting right next to the first one,
    and they both share that zeroth chopstick. With this arrangement, it?
    s possible at some point for all the philosophers to be trying to eat
    and waiting on the philosopher next to them to put down their
    chopstick, and the program will deadlock.
    -->
    <para>

    </para>

    <!--
    If your threads (philosophers) are spending more time on other tasks
    (thinking) than eating, then they have a much lower probability of
    requiring the shared resources (chopsticks), and thus you can convince
    yourself that the program is deadlock free (using a nonzero ponder
    value), even though it isn?t.
    -->
    <para>

    </para>

    <!--
    To repair the problem, you must understand that deadlock can occur if
    four conditions are simultaneously met:
    -->
    <para>

    </para>

    <!--
    1.  Mutual exclusion. At least one resource used by the threads must
    not be shareable. In this case, a chopstick can be used by only one
    philosopher at a time.
    -->
    <para>

    </para>

    <!--
    2.  At least one process must be holding a resource and waiting to
    acquire a resource currently held by another process. That is, for
    deadlock to occur, a philosopher must be holding one chopstick and
    waiting for another one.
    -->
    <para>

    </para>

    <!--
    3.  A resource cannot be preemptively taken away from a
    process. Processes only release resources as a normal event. Our
    philosophers are polite and they don?t grab chopsticks from other
    philosophers.
    -->
    <para>

    </para>

    <!--
    4.  A circular wait can happen, whereby a process waits on a resource
    held by another process, which in turn is waiting on a resource held
    by another process, and so on, until one of the processes is waiting
    on a resource held by the first process, thus gridlocking
    everything. In DeadlockingDiningPhilosophers.cpp, the circular wait
    happens because each philosopher tries to get the right chopstick
    first and then the left.
    -->
    <para>

    </para>

    <!--
    Because all these conditions must be met to cause deadlock, you need
    to stop only one of them from occurring to prevent deadlock. In this
    program, the easiest way to prevent deadlock is to break condition
    four. This condition happens because each philosopher is trying to
    pick up their chopsticks in a particular sequence: first right, then
    left. Because of that, it?s possible to get into a situation where
    each of them is holding their right chopstick and waiting to get the
    left, causing the circular wait condition. However, if the last
    philosopher is initialized to try to get the left chopstick first and
    then the right, that philosopher will never prevent the philosopher on
    the immediate right from picking up their left chopstick. In this
    case, the circular wait is prevented. This is only one solution to the
    problem, but you could also solve it by preventing one of the other
    conditions (see advanced threading books for more details):
    -->
    <para>

    </para>


//: V2C11:FixedDiningPhilosophers.cpp {RunByHand}


    <!--
    By ensuring that the last philosopher picks up and puts down their
    left chopstick before their right, the deadlock is removed, and the
    program will run smoothly.
    -->
    <para>

    </para>

    <!--
    There is no language support to help prevent deadlock; it?s up to you
    to avoid it by careful design. These are not comforting words to the
    person who?s trying to debug a deadlocking program.
    -->
    <para>

    </para>

  </sect1>
  <sect1>
    <!-- : Summary -->
    <title>Resumen</title>

    <!--
    The goal of this chapter was to give you the foundations of concurrent
    programming with threads:
    -->
    <para>

    </para>

    <!-- 1.  You can run multiple independent tasks. -->
    <para>

    </para>

    <!--
    2.  You must consider all the possible problems when these tasks shut
    down. Objects or other tasks may disappear before tasks are finished
    with them.
    -->
    <para>

    </para>

    <!--
    3.  Tasks can collide with each other over shared resources. The mutex
    is the basic tool used to prevent these collisions.
    -->
    <para>

    </para>

    <!-- 4.  Tasks can deadlock if they are not carefully designed. -->
    <para>

    </para>

    <!--
    However, there are multiple additional facets of threading and tools
    to help you solve threading problems. The ZThreads library contains a
    number of these tools, such as semaphores and special types of queues,
    similar to the one you saw in this chapter. Explore that library as
    well as other resources on threading to gain more in-depth knowledge.
    -->
    <para>

    </para>

    <!--
    It is vital to learn when to use concurrency and when to avoid it. The
    main reasons to use it are:
    -->
    <para>

    </para>

    <!--
    · To manage a number of tasks whose intermingling use the computer
    more efficiently (including the ability to transparently
    distribute the tasks across multiple CPUs).
    -->
    <para>

    </para>

    <!-- · To allow better code organization. -->
    <para>

    </para>

    <!-- · To be more convenient for the user. -->
    <para>

    </para>

    <!--
    The classic example of resource balancing is to use the CPU during I/O
    waits. The classic example of user convenience is to monitor a ?stop?
    button during long downloads.
    -->
    <para>

    </para>

    <!--
    An additional advantage to threads is that they provide ?light?
    execution context switches (on the order of 100 instructions) rather
    than ?heavy? process context switches (thousands of
    instructions). Since all threads in a given process share the same
    memory space, a light context switch changes only program execution
    and local variables. A process change?the heavy context switch?must
    exchange the full memory space.
    -->
    <para>

    </para>

    <!-- The main drawbacks to multithreading are: -->
    <para>

    </para>

    <!-- · Slowdown occurs while waiting for shared resources. -->
    <para>

    </para>

    <!-- · Additional CPU overhead is required to manage threads. -->
    <para>

    </para>

    <!-- · Unrewarded complexity arises from poor design decisions. -->
    <para>

    </para>

    <!--
    · Opportunities are created for pathologies such as starving, racing,
    deadlock, and livelock.
    -->
    <para>

    </para>

    <!--
    · Inconsistencies occur across platforms. When developing the original
    material (in Java) for this chapter, we discovered race
    conditions that quickly appeared on some computers but wouldn?
    t appear on others. The C++ examples in this chapter behaved
    differently (but usually acceptably) under different operating
    systems. If you develop a program on a computer and things seem
    to work right, you might get an unwelcome surprise when you
    distribute it.
    -->
    <para>

    </para>

    <!--
    One of the biggest difficulties with threads occurs because more than
    one thread might be sharing a resource?such as the memory in an
    object?and you must make sure that multiple threads don?t try to read
    and change that resource at the same time. This requires judicious use
    of synchronization tools, which must be thoroughly understood because
    they can quietly introduce deadlock situations.
    -->
    <para>

    </para>

    <!--
    In addition, there?s a certain art to the application of threads. C++
    is designed to allow you to create as many objects as you need to
    solve your problem?at least in theory. (Creating millions of objects
    for an engineering finite-element analysis, for example, might not be
    practical.) However, there is usually an upper bound to the number of
    threads you?ll want to create, because at some number, threads may
    become balky. This critical point can be difficult to detect and will
    often depend on the OS and thread library; it could be fewer than a
    hundred or in the thousands. As you often create only a handful of
    threads to solve a problem, this is typically not much of a limit; but
    in a more general design it becomes a constraint.
    -->
    <para>

    </para>

    <!--
    Regardless of how simple threading can seem using a particular
    language or library, consider it a black art. There?s always something
    you haven?t considered that can bite you when you least expect
    it. (For example, note that because the dining philosophers problem
    can be adjusted so that deadlock rarely happens, you can get the
    impression that everything is OK.) An appropriate quote comes from
    Guido van Rossum, creator of the Python programming language:
    -->
    <para>

    </para>

    <!--
    In any project that is multithreaded, most bugs will come from
    threading issues. This is regardless of programming language?it?s a
    deep, as yet un-understood property of threads.
    -->
    <para>

    </para>

    <!--
    For more advanced discussions of threading, see Parallel and
    Distributed Programming Using C++, by Cameron Hughes and Tracey
    Hughes, Addison Wesley 2004.
    -->
    <para>

    </para>

  </sect1>
  <sect1>
    <!-- : Exercises -->
    <title>Ejercicios</title>

    <!--
    Solutions to selected exercises can be found in the electronic
    document The Thinking in C++ Volume 2 Annotated Solution Guide,
    available for a small fee from www.MindView.net.
    -->
    <para>

    </para>

    <!--
    1.  Inherit a class from Runnable and override the run( )
    function. Inside run( ), print a message, and then call sleep(
    ). Repeat this three times, and then return from run( ). Put a
    start-up message in the constructor and a shut-down message when the
    task terminates. Make several thread objects of this type, and run
    them to see what happens.
    -->
    <para>

    </para>

    <!--
    2.  Modify BasicThreads.cpp to make LiftOff threads start other
    LiftOff threads.
    -->
    <para>

    </para>

    <!--
    3.  Modify ResponsiveUI.cpp to eliminate any possible race
    conditions. (Assume bool operations are not atomic.)
    -->
    <para>

    </para>

    <!--
    4.  In Incrementer.cpp, modify the Count class to use a single int
    instead of an array of int. Explain the resulting behavior.
    -->
    <para>

    </para>

    <!--
    5.  In EvenChecker.h, correct the potential problem in the Generator
    class. (Assume bool operations are not atomic.)
    -->
    <para>

    </para>

    <!--
    6.  Modify EvenGenerator.cpp to use interrupt( ) instead of quit
    flags.
    -->
    <para>

    </para>

    <!--
    7.  In MutexEvenGenerator.cpp, change the code in
    MutexEvenGenerator::nextValue( ) so that the return expression
    precedes the release( ) statement and explain what happens.
    -->
    <para>

    </para>

    <!--
    8.  Modify ResponsiveUI.cpp to use interrupt( ) instead of the
    quitFlag approach.
    -->
    <para>

    </para>

    <!--
    9.  Look up the Singleton documentation in the ZThreads
    library. Modify OrnamentalGarden.cpp so that the Display object is
    controlled by a Singleton to prevent more than one Display from being
    accidentally created.
    -->
    <para>

    </para>

    <!--
    10.  In OrnamentalGarden.cpp, change the Count::increment( ) function
    so that it does a direct increment of count (that is, it just does a
    count++). Now remove the guard and see if that causes a failure. Is
    this safe and reliable?
    -->
    <para>

    </para>

    <!--
    11.  Modify OrnamentalGarden.cpp so that it uses interrupt( ) instead
    of the pause( ) mechanism. Make sure that your solution doesn?t
    prematurely destroy objects.
    -->
    <para>

    </para>

    <!--
    12.  Modify WaxOMatic.cpp by adding more instances of the Process
    class so that it applies and polishes three coats of wax instead of
    just one.
    -->
    <para>

    </para>

    <!--
    13.  Create two Runnable subclasses, one with a run( ) that starts and
    calls wait( ). The other class?s run( ) should capture the reference
    of the first Runnable object. Its run( ) should call signal( ) for the
    first thread after some number of seconds have passed so that first
    thread can print a message.
    -->
    <para>

    </para>

    <!--
    14.  Create an example of a ?busy wait.? One thread sleeps for awhile
    and then sets a flag to true. The second thread watches that flag
    inside a while loop (this is the ?busy wait?) and, when the flag
    becomes true, sets it back to false and reports the change to the
    console. Note how much wasted time the program spends inside the ?busy
    wait,? and create a second version of the program that uses wait( )
    instead of the ?busy wait.? Extra: run a profiler to show the time
    used by the CPU in each case.
    -->
    <para>

    </para>

    <!--
    15.  Modify TQueue.h to add a maximum allowable element count. If the
    count is reached, further writes should be blocked until the count
    drops below the maximum. Write code to test this behavior.
    -->
    <para>

    </para>

    <!--
    16.  Modify ToastOMaticMarkII.cpp to create peanut-butter and jelly on
    toast sandwiches using two separate assembly lines and an output
    TQueue for the finished sandwiches. Use a Reporter object as in
    CarBuilder.cpp to display the results.
    -->
    <para>

    </para>

    <!--
    17.  Rewrite C07:BankTeller.cpp to use real threading instead of
    simulated threading.
    -->
    <para>

    </para>

    <!--
    18.  Modify CarBuilder.cpp to give identifiers to the robots, and add
    more instances of the different kinds of robots. Note whether all
    robots get utilized.
    -->
    <para>

    </para>

    <!--
    19.  Modify CarBuilder.cpp to add another stage to the car-building
    process, whereby you add the exhaust system, body, and fenders. As
    with the first stage, assume these processes can be performed
    simultaneously by robots.
    -->
    <para>

    </para>

    <!--
    20.  Modify CarBuilder.cpp so that Car has synchronized access to all
    the bool variables. Because Mutexes cannot be copied, this will
    require significant changes throughout the program.
    -->
    <para>

    </para>

    <!--
    21.  Using the approach in CarBuilder.cpp, model the house-building
    story that was given in this chapter.
    -->
    <para>

    </para>

    <!--
    22.  Create a Timer class with two options: (1) a one-shot timer that
    only goes off once (2) a timer that goes off at regular intervals. Use
    this class with C10:MulticastCommand.cpp to move the calls to
    TaskRunner::run( ) from the procedures into the timer.
    -->
    <para>

    </para>

    <!--
    23.  Change both of the dining philosophers examples so that the
    number of Philosophers is controlled on the command line, in addition
    to the ponder time. Try different values and explain the results.
    -->
    <para>

    </para>
  </sect1>
</chapter>
